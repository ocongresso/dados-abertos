{
  "id": 72827,
  "start_time": 1715247133,
  "end_time": 1715259429,
  "title": "CÂMARA DOS DEPUTADOS - OUTROS EVENTOS",
  "description": "09/05/2024 - Congresso Inteligência Artificial e Eleições",
  "speeches": [
    {
      "id": 4104302,
      "start_time": 1715247133,
      "duration": 103,
      "transcription": "",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104327,
      "start_time": 1715247236,
      "duration": 378,
      "transcription": "Dia senhoras e senhores. Em dois mil e vinte e quatro, a gente está discutindo tema fundamental que assola o país. Dois mil e vinte e quatro será ano crucial para a história das democracias representativas em todo o mundo de acordo com o centro para o progresso americano o instituto de pesquisa nos Estados Unidos, este ano será o maior ano eleitoral da história. Mais de dois bilhões de pessoas devem ir às urnas, compreendendo quase oitenta oitenta países, que juntos representam mais da metade da população mundial. Como sabemos, o Brasil com seu mais de cento e cinquenta milhões de eleitores aptos a votar, está nesse grupo. Em outubro realizaremos nossas eleições municipais. Dois mil e vinte e quatro não será ano, não será só ano crucial para a história das democracias apenas por este motivo. Neste ano, teremos de enfrentar dos maiores e mais complexos desafios apresentados à democracia no século vinte e a inteligência artificial. Nos últimos anos, a inteligência artificial evoluiu de tão forma assustadora que se tornou praticamente impossível não ler ou ouvir notícias alarmantes sobre os perigos dessa tecnologia. Agora, os problemas vão muito além das famosas fake news, já não são poucos os casos em diversos países disseminação de deepfakes extremamente realistas, que engana os eleitores e deturpam as campanhas políticas há poucos dias da eleição. Isso sem falar no potencial dos algoritmos de IA de manipular os usuários das plataformas digitais para determinados fins políticos, como ficou evidenciado no escândalo da Cambridge Analítica. No entanto, embora esses riscos apresentado pela IA, a democracias sejam inegociáveis. Não podemos fechar os olhos para os benefícios que a tecnologia pode trazer, inclusive para o fortalecimento da própria democracia, como alguns especialistas no país têm apontado, a inteligência artificial pode ser instrumento muito eficaz para a redução de custo nas campanhas eleitorais, democratizando ainda mais o processo político. Quando discutimos o caminho que o Brasil deve seguir na regulamentação da inteligência artificial, devemos evitar o alarmismo e o pessimismo, prezando por uma abordagem realista e plural da inteligência artificial. Devemos tentar minimizar o máximo os seu risco, mas sempre com cautela, buscando uma estratégia regulatória que incentive, na medida do possível, a inovação baseada em A, nos mais variados setores. Só assim criaremos ambiente jurídico favorável ao posicionamento do Brasil como potencial protagonista no cenário global da inteligência artificial. Isso significa que a regulação das novas tecnologias digitais, incluindo a IA, deve ser vista não como entrava em inovação, mas sim como sua aliada, na medida que traz segurança jurídica necessária para o empreendedorismo, e o desenvolvimento tecnológico ao mesmo tempo, em que protege os usuários e a sociedade contra os seus potenciais risco. Como deputado federal, ao longo de quatro mandatos, desenvolvi e sigo desenvolvendo longo trabalho com temas relacionados a novas tecnologias digitais, e seus impactos sociais. Dentre outras iniciativas, fui autor do PL vinte e três 0 três de dois mil e quinze, atual lei catorze mil quatrocentos e setenta e oito de dois mil e vinte e dois, que disciplina o mercado de criptomoedas no Brasil, Presidi a CPI das Pirâmides Financeiras, e estou atento a preocupações geradas por novas tecnologias no país, e sempre em busca de propor soluções legislativas que equilibrem, de lado, a proteção dos brasileiros e brasileiras, e de outro, o estímulo a nova a novas tecnologias. O evento de hoje, organizado por iniciativa do Solidariedade, reflete especialmente a necessidade de se discutir a regulação da inteligência artificial no país, levando em conta as múltiplas faces dessas dessa tecnologia. Reunimos aqui qualificados acadêmicos, atores do setor público e representantes de Big Tech, para uma promissora troca de ideias, a qual certamente renderá frutos valiosos, para o desenho da regulação da IA no campo eleitoral. Faltam faltam poucos meses para eleições municipais, e é fundamental promovermos o debate, como os que como os que teremos hoje aqui. A fim de que possamos pensar e construir proposta regulatórias eficazes para a preservação de nossas instituições democrática. Para muitas dúvidas sobre o futuro da humanidade, diante das maravilhas e dos pesadelos que aí a proporciona. Há uma certeza, tema tão amplo e complexo não pode ser definido de forma tão precipitada. Deve devese promover, na maior medida possível, amplo e plural debate na sociedade brasileira, sob pena de conduzirmos o país em uma direção perigosa, em que deixamos de aproveitar os benefícios da tecnologia e nos tornemos refém dos seus risco. Espero que as discussões no evento de hoje contribua para que encontremos soluções regulatórias que proporcionem uma poderosa aliança entre a tecnologia e a nossa democracia. Muito obrigado a todos os participantes. Esse é evento fundamental no momento que vamos enfrentar em outubro, e agradeço a presença de todos, e bom evento para todos.",
      "summary": " Deputado propõe abordagem realista de IA, minimizando riscos e incentivando inovação, com foco em regulação para eleições democráticas e proteção a usuários.",
      "speaker": {
        "id": 160512,
        "name": "Aureo Ribeiro",
        "position": "Deputado",
        "slug": "aureo-ribeiro"
      }
    },
    {
      "id": 4104305,
      "start_time": 1715247614,
      "duration": 11,
      "transcription": "Obrigado deputado Áureo, eu passo a palavra agora pra deputada Gisela Simona, que vai fazer as suas considerações.",
      "summary": " Mestre de Cerimônias encoraja participação, passa a palavra para deputada Gisela Simona.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104311,
      "start_time": 1715247625,
      "duration": 93,
      "transcription": "Bom dia a todos. Na verdade deputado Áureo, a minha fala é primeiro de agradecimento, né, ao Solidariedade ao Partido Solidariedade aqui representado por vossa excelência, né, porque o tema é o dos mais atuais, né, falar de inteligência artificial nesse momento que no antecipa as eleições de dois mil e vinte e quatro é algo que toda a sociedade principalmente a classe política está sedenta de informação e proporcionar esse debate com técnicos na área, com especialistas nessa área será fundamental pra nosso aprendizado, então aqui na verdade a gente traz pouco da angústia principalmente de quem é précandidato hoje nessas eleições né com o que vem de novo, mas ao mesmo tempo entendendo que essas novas ferramentas digitais são grandes aliadas nossas mas que precisamos sim de mais informação e essa casa precisa se aprofundar porque hoje nós temos normas regulatórias do ponto de vista aí do Tribunal Superior Eleitoral mas daqui a pouco certamente como já tem dentro da casa no Senado tramitando projeto de lei nesse sentido virá aqui para a câmara dos deputados e quanto mais conhecimento tivermos na área será fundamental aí pro nosso aprendizado e acertarmos na norma regulatória tem parabéns aí a todos que estão se dispondo a fazer essa discussão e contribuir com o debate. Obrigada. Obrigada deputada Gisela passo",
      "summary": " A deputada agradece e valoriza a importância do debate sobre inteligência artificial na política, reconhecendo sua complexidade e o potencial das novas ferramentas digitais, enquanto se prepara para uma próxima discussão e regulamentação em conjunto com especialistas no assunto.",
      "speaker": {
        "id": 226179,
        "name": "Gisela Simona",
        "position": "Deputada",
        "slug": "gisela-simona"
      }
    },
    {
      "id": 4104307,
      "start_time": 1715247718,
      "duration": 8,
      "transcription": "Todas e todos, agradeço aqui a fala de todos os painelistas, contribuições muito boas e que, ressaltam a complexidade realmente do tema da inteligência artificial, né, a gente precisa evitar visões simplistas ou alarmistas, precisamos sempre ter em mente também os benefícios da tecnologia, e além disso como acho que todos mencionaram aqui, a gente tem falado muito de deepfake ultimamente porque é o risco mais, digamos assim, aparente que a gente vê mais na mídia, relacionado a a eleições, né? Mas existe também, além da iagenerativa que está na moda, aí a preditiva, né, né, que é o que está por trás por exemplo dos das redes sociais, é justamente o que permite a detecção dos vulneráveis como professor Juliano falou e também o micro direcionamento de informações e propaganda como o professor Alisson destacou. Então eu queria aqui explorar com os três panelistas outro, assim, outro tipo de risco que alguns estudiosos da Inteligência Artificial, de ética na Inteligência Artificial de fora do Brasil também tem tem comentado, que é não exatamente o risco da IA pra pras eleições, mas pra democracia como todo. Como a inteligência artificial é capaz de afetar a liberdade de expressão, que é direito fundamental, tá no artigo quinto da nossa constituição, de forma que, enfim, todo esse debate sobre regulação da IA não pode perder de vista também a preservação da liberdade de expressão. No caso, o risco que a IA pode apresentar a liberdade de expressão, e eu queria ver se os painelistas concordam, está mais no campo da IA preditiva, porque como as redes sociais, o modelo de negócio das redes sociais que hoje são o ambiente onde maior parte das pessoas formam sua opinião, são movidos pela chamada economia da atenção, que o objetivo ali é maximizar o tempo do do usuário usando a rede, de forma que a estratégia mais efetiva é sempre direcionar ele informações que ele considera positivas, ou seja, no caso da da das eleições, isso acaba por gerar o que se chama de câmara de eco, quer dizer, a a pessoa que tem determinado viés político político ideológico acaba vendo sempre as informações que são do agrado dela, de forma que isso acabaria por, assim, acabaria por piorar o problema da da polarização, porque a Então eu queria ver a opinião dos dos painelistas, se eles acham que efetivamente a IA pode representar problema à liberdade de expressão nesse sentido, na medida em que ela cria maior ambiente de polarização, e se eles concordam de que forma a gente deveria endereçar isso, se as resoluções do TSE já lidam com isso de alguma forma, se a gente deveria lidar com isso por meio de do PL de inteligência artificial ou do PL das fake news, como a gente deveria lidar com esse com esse tipo de risco da IA, a liberdade de expressão. Não sei se alguém quer falar primeiro ou se a gente segue a ordem. Bom, obrigada Caio pela pergunta, é uma pergunta",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104299,
      "start_time": 1715247726,
      "duration": 550,
      "transcription": "",
      "speaker": {
        "name": "Lílian de Melo",
        "position": "Secretária de Assuntos Digitais - MJ"
      }
    },
    {
      "id": 4104310,
      "start_time": 1715248276,
      "duration": 121,
      "transcription": "Obrigado, Doutora Lilian. Com isso, a não ser que o presidente do deputado Áureo queira fazer ou a deputada Gisela queira fazer alguma consideração adicional, a gente vai dissolver a primeira mesa e chamar o primeiro painel. Muito obrigado. Pra compor agora o primeiro painel, eu gostaria de chamar o primeiro o primeiro painel do evento, que vai acontecer agora, vai ser painel que vai discutir benefícios e riscos da inteligência artificial, no âmbito eleitoral e as resoluções do Tribunal Superior Eleitoral. Para compor o painel e compor a mesa, eu gostaria de convidar o Alisson Possa, professor do IBMEC, a Heloísa Massaro, do InternetLab, o professor Juliano Maranhão, da Faculdade de Direito da Universidade de São Paulo, e o Caio Misaja, que é mestrando em Direito na Universidade de São Paulo, na área, e que muito ajudou a organizar o evento. Passo então, composta a mesa, passo então a palavra a Heloísa Massaro do InternetLab pra fazer as suas considerações iniciais.",
      "summary": " Mestre de Cerimônias anuncia dissolução da primeira mesa e convoca o primeiro painel para discutir benefícios e riscos da inteligência artificial no âmbito eleitoral, introduzindo os participantes Alisson Possa, Heloísa Massaro, Juliano Maranhão e Caio Misaja; dá a palavra a Heloísa Massaro para iniciar o painel.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104342,
      "start_time": 1715248397,
      "duration": 853,
      "transcription": "Todos, primeiro eu queria agradecer ao convite pra participação no evento de hoje e queria cumprimentar a todos aqui presentes. Enfim as considerações iniciais da doutora Lilian foram muito muito bem colocadas, no sentido dessa ponderação entre potencialidades e riscos, né, e eu acho que o que eu tinha pensado em falar complementa muito isso no sentido de tentar traçar pouco esse panorama, onde a gente olha pra usos, riscos, o que que a gente tem de desafios, de movimentos regulatórios, né. E daí eu acho que o primeiro passo é entender porque que a gente tem falado tanto de inteligência inteligência artificial ele data de pelo menos desde a metade do século passado, né, então a gente já tinha movimentos de desenvolvimento de inteligência artificial nos anos sessenta, setenta, oitenta, noventa, mas o que aconteceu nesses últimos anos, né. Então o que a gente observa é que essas tecnologias foram ficando cada vez melhores. E não só isso, eu acho que o principal é que a gente teve uma ampliação de acesso a essas tecnologias, né, se tornou muito mais fácil utilizar essas tecnologias, elas passaram a estar disponíveis pra usuários de forma geral, e isso reduziu bastante os custos e tornou mais fácil esse uso. E eu acho que o principal movimento que a gente pode observar, pelo menos nos últimos meses ou no último ano, é sobretudo essa disseminação do que a gente chama de inteligência artificial generativa, né, que vão estar, enfim, essas ferramentas de inteligência artificial que são mais amplamente difundidas como ChatGPT, etcétera. Mas quando a gente está falando de inteligência artificial em eleições, e quando a gente está falando de inteligência artificial é tema que ele vai muito além da inteligência artificial generativa, né, e também muito além dos riscos relacionados à fabricação de conteúdos falsos. Quando a gente pensa em inteligência artificial ela é campo extremamente amplo com múltiplas funcionalidades. E quando a gente olha pra ela no âmbito de eleições, existem de fato muitas potencialidades né, como a própria doutora Lilian pontuou, né. Então inteligência artificial pode ser utilizada pra otimizar tarefas de campanhas, para facilitar a identificação de prioridades, pra diversas tarefas que estão envolvidas aí no campo da política e das eleições mesmo, né. Inclusive quando a gente pensa em agenerativa, você tem o potencial de facilitar a produção de conteúdos como por exemplo, facilitar a produção de santinhos ou de logomarcas, logomarcas não né, mas de vinhetas, materiais que antes talvez requeressem custo muito maior por exigirem design, etcétera, podem se tornar de fato muito mais fáceis em reduzir os custos de uma campanha, né, e é interessante que o próprio Tribunal Superior Eleitoral reconhece isso, quando ele traz as resoluções né, a prova resoluções esse ano, onde ele exige a transparência sobre conteúdos produzidos por inteligência artificial, sem necessariamente vedar todo o uso, mas sobretudo quando ele cria exceção a essa regra, então para por causa de conteúdos que são tidos como de menor risco né que são esses conteúdos né? Por outro lado, quando a gente pensa em novas tecnologias né, elas trazem muitos potenciais, e esses potenciais eles acabam tendo pouco esse viés duplo, porque da mesma forma que pode ser se tornar mais fácil criar conteúdos para uma campanha, uma campanha ficar mais barata também é muito mais fácil você eventualmente fabricar conteúdos que podem manipular uma eleição, enfim, ela vai trazer esses riscos. E é interessante olhar para esses riscos pouco além da IA generativa e da desinformação, e daí eu acho que enfim, vou passar aqui pouco pra alguns desses pontos, começando quando a gente está olhando pra Inteligência Artificial e eventualmente dinâmicas de predição ou de persuasão, né? Se a gente se recorda em dois mil e dezesseis a gente tem viu escândalo da Cambridge Analítica, nos Estados Unidos e no Reino Unido pelo uso de sistemas de análise psicométrica na época né, com a ideia de persuadir ou eventualmente de manipular o eleitorado né. Isso é risco que, enfim, é possível existir com ferramentas de inteligência artificial no âmbito de tratamento de dados, de buscar enfim, manipular o preço ativo eleitor. Mas nesse âmbito é importante a gente não esquecer que no Brasil a gente já tem regime de proteção de dados que ele auxilia em muito nesse âmbito de tratamento legal de dados pessoais, né, então porque campanhas E0E0 TSE estabeleceu diálogos muito importantes com esse regime de proteção de dados pessoais nas resoluções, nas últimas três resoluções aprovadas né, então a gente vai ter regras relacionadas à base legal que é necessária pra uma campanha tratar dados, na própria regulação de proteção de dados a gente vai ter o princípio da necessidade que ele é muito importante quando você está olhando pra esse tratamento excessivo de dados, porque quando a gente fala de necessidade a gente fala de tratar o mínimo necessário, né. E será que tratamento excessivo de dados pra pra mapear o perfil psicométrico, psicológico, comportamental dos candidatos é o mínimo necessário, né, dos eleitores. E a gente vai ter regras de transparências que são muito importantes, né. Bom, pra além desse campo aí a gente vai entrar no campo da emaginerativa que é o que a gente vem discutindo mais, e os riscos estão principalmente relacionados à fabricação de conteúdo pra manipulação e a gente tem três exemplos bastante recentes, no âmbito de eleições internacionais. O primeiro mais conhecido foi nos Estados Unidos com a fabricação de áudio do presidente Joe Biden, falando que as pessoas não precisariam voltar nas primárias porque o que valia era só o voto nas eleições mesmo, e era áudio falso que buscava dissuadir eleitores e esse comportamento de buscar dissuasão de eleitores é muito comum nos Estados Unidos pela falta de obrigatoriedade do voto. A gente teve caso muito famoso na Eslováquia com vídeo falso que foi divulgado sobre candidato que estava estava entre os dois primeiros colocados, onde ele supostamente discutia compra de votos né, esse vídeo era claramente falso, só que ele foi divulgado às vésperas do dia da votação. É difícil analisar o impacto mas algumas alguns especialistas dizem que pode ter tido impacto pela grande proximidade que ele estava do outro morreram. Figuras públicas é que já morreram, então a fabricação de imagens, áudios e vídeos envolvendo essas pessoas em apoio a candidatos, né. E daí que voltando né pro nosso cenário nacional, eu acho que a gente pode olhar pros elementos que podem trazer maior risco quando a gente está pensando nisso, né. E eu acho que dos primeiros elementos daí quando a gente está pensando em medidas pra mitigação e que que a gente tem de caminhos regulatórios, é interessante olhar pra esses elementos né. A gente tem elemento aí de tempo né, porque existe risco muito maior quando esses conteúdos são divulgados muito próximos dias das eleições, porque o tempo pra se analisar ou pra se verificar a veracidade disso ele acaba sendo muito reduzido e é muito comum que esse tipo de conteúdo sensacionalista fabricado seja muitas vezes divulgado muito próximo ao dia das eleições né. E daí dialogando com uma pesquisa que a gente tem no InternetLab sobre consumo de informação em aplicativos de mensagem, onde a gente olha pra perspectiva do usuário, a gente observa que em geral as pessoas elas buscam verificar a fonte da informação, né, com uma ressalva de que cada considera a fonte uma coisa diferente. Mas quando a gente está falando de conteúdos apelativos e sensacionalistas com esse senso de urgência muitas vezes as pessoas repassam sem se importar se de fato é verdade ou mentira, né. E quando a gente pensa nesse tipo de conteúdo vinculado próximo ao dia da eleição, isso é risco ampliado. Agora quando a gente está falando de eleições municipais, e a gente olha pro Brasil e pra municípios menores e no número, enfim imenso de eleições que a gente tem, a gente tem risco relacionado a fatos que a gente tem muitos desertos de notícias. Então muitos desses municípios eles estão em localidades lá onde não se tem produção, onde não se tem o veículo veículos jornalísticos ou não, onde não se tem veículos jornalísticos independentes, então onde a própria divulgação de fatos ela é muito escassa, e a capacidade de identificação do que é manipulado ou não ela acaba sendo bastante reduzida né, e isso é tema importantíssimo pra pras próximas eleições, E daí nesse sentido eu acho que o Tribunal Superior Eleitoral ele dá passo muito importante de fato quando ele reconhece a existência dessas novas tecnologias e do uso delas no âmbito político eleitoral e vai estabelecer regras iniciais sobretudo envolvendo transparência né. Então o TSE vai estabelecer ali a obrigação de rotulação de conteúdos criados por Inteligência Artificial e vedar alguns usos que foi eles que o Tribunal considerou de mais alto risco como, é o que a gente conhece como deepfake né, e daí pra finalizar eu acho que tem alguns desafios que eu acho que se colocam mais para além desses riscos iniciais mapeados, envolvendo sobretudo inteligência artificial generativa e integridade eleitoral, e que envolvem pouco essa perspectiva de olhar pro usuário e pra como ele consome informação, né, porque existe uma preocupação muito grande do conteúdo que vai manipular, e do conteúdo falso que circula, etcétera, mas o que a gente observa nas pesquisas que a gente faz nos últimos três, quatro anos envolvendo o consumo de informação política pelo usuário é que as pessoas elas estão de fato muito preocupadas em checar informação e checar a fonte, né. O que vai mudar de fato que as pessoas consideram como fonte, né. E daí muitas vezes tem elemento que é muitas vezes esse tipo de conteúdo mais do que enganar ele serve muito mais para reforço de viés, porque conteúdo fabricado ele pode não convencer uma pessoa que, tenha uma visão políticaideológica ou que tenham viés contrário aquilo que está sendo dito lá, mas muitas vezes importa pouco pra uma pessoa que se alinha ao que está naquele conteúdo se ele é de fato falso ou verdadeiro. Muitas vezes esse conteúdo funciona muito mais para reforço de viés, né. E quando a gente pensa também na fato de, enfim, toda essa gramática de checagem ela é muito disseminada entre usuários de uma forma geral, você também tem que considerar que a longo prazo existe risco de desenvolvimento do ceticismo, por lado né, a gente enxerga que muito provavelmente existe uma tendência das pessoas cada vez mais é desconfiarem de imagens, vídeos e áudios que cheguem preocupadas que podem ser fabricados, né. A gente observou isso de dois mil e dezoito até, enfim, recentemente com notícias de forma geral, então a gente. Então a a gente observou nesses últimos anos como as pessoas foram ficaram foram ficando cada vez mais céticas com relação à notícia e preocupada se a notícia era de fato verdadeira ou não, então é possível que elas desenvolvam esse de comportamento com relação a imagens, vídeos e áudios, né. Por outro lado existe o 0 efeito colateral disso que é desenvolver generalizado, onde as pessoas deixem de acreditar em qualquer tipo de áudio, vídeo, e imagem, e o desenvolvimento enfim, a verificação de se aquilo é verdade ou não ou no que acreditar, passe de novo por esse viés de confirmação. Daí a gente tem caso muito recente nos Estados Unidos onde a gente já observou isso acontecendo, onde o expresidente Trump ele acusou vídeo que era verdadeiro, que foi divulgado pra uma campanha de primárias, de opositor nas primárias dele, onde ele acusou aquele vídeo de ser vídeo deepfake apesar de ser vídeo verdadeiro, né, então isso também é algo a se levar em consideração a própria manipulação ou a própria mobilização, instrumentalização dessa discussão sobre o que é verdadeiro ou falso como parte da disputa política, enfim, essas foram pouco as minhas considerações iniciais, obrigada.",
      "summary": " Dra. InternetLab discutiu IA em eleições: vantagens como otimização de tarefas e redução de custos, mas também riscos como manipulação e deepfakes. Recomenda cautela com dados pessoais e transparência. Destaca importância de identificar e mitigar riscos relacionados a eleições e informação sensacionalista, podendo causar descrença em mídias.",
      "speaker": {
        "name": "Heloísa Massaro",
        "position": "Dra. InternetLab"
      }
    },
    {
      "id": 4104301,
      "start_time": 1715249250,
      "duration": 11,
      "transcription": "",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104314,
      "start_time": 1715249261,
      "duration": 1110,
      "transcription": "Bom dia a todos, e todas, ah isso eu ia pedir a a minha a apresentação, tem o 0, como eu trocar os slides? Ah não, ali é é é apresentação da Tainá. Ok. E pra eu trocar os slides? Ah minuto. Bom então enquanto, enquanto o problema é resolvido. Como eu quero abordar o tema, não é? Sobre benefícios e riscos da inteligência artificial versus, Está correto eu só preciso do aparelinha pra trocar os slides. Isso. Bom, então como eu quero abordar o tema, da regulação da inteligência artificial nas eleições considerando seus benefícios e riscos. A inteligência artificial como a Lilian já deixou, claro e a, Heloísa também, é uma tecnologia dual. Portanto qualquer esforço de regulação, deve atentar, na medida que a regulação pode trazer proibições a certas práticas, Deve atentar pra ser extremamente cirúrgica e atacar exatamente a preocupação, com o emprego da tecnologia e o resultado, que pode ser deletério. Sob pena de trazer proibições sobre inclusivas que restrinjam a possibilidade da tecnologia desenvolver e produzir os seus benefícios. Então posso trocar? Ah tá. Ok, eles estão trocando as slides pra então. Bom, e eu acho interessante começar com uma alegoria. Que é trazida por essa obra do Dostoevsky, os irmãos Karamazov é dos grandes clássicos do do romantismo psicológico. Porque ela versa sobre escândalo, e na verdade o que nós, nos preocupamos quando foco em regular a inteligência judicial nas eleições está no papel dos escândalos pra virar o jogo e determinar o jogo das eleições isso acontece nas mídias tradicionais acontecia, mas acontece agora nas novas mídias também com sentido distinto, Então eu quero trabalhar com vocês a ideia do que que é o novo sentido de escândalo, e qual o papel da inteligência artificial pra produzir, esses escândalos? Por isso eu coloquei o nome na palestra de e escândalo, é uma nova forma de escândalo. O, a história dos irmãos Kramazov esse livro traz, grande escândalo de produção nacional já trabalhado pela imprensa, em função de algo que acontece ali localmente que é o parricídio, né? Supostamente provocado pelo pelo Dmitry Karramazov. E o que é interessante, nessa obra é essa oposição entre a racionalidade e a irracionalidade que leva a erro de julgamento. O último capítulo do livro, o título é erro de julgamento, e trata de pode trocar o slide? Tá e trata as cenas normalmente de ilustração desse episódio têm essa cara, de racionalidade meio psicodélica, porque o 0 julgamento é completo desvario, não é? Em que a irracionalidade provocada por aquele escândalo e principalmente pela palavra parrigídio pela força da palavra parrigídio, distorce completamente, o juízo, não é? E, é interessante que a obra trata o escândalo num sentido tradicional, que na verdade é o uso, que nós temos da palavra escândalo atualmente. Pode trocar o slide. Tem livro interessante do Johannes Ehat que faz uma análise semiótica do significado da palavra escândalo, né e como ele é construído. E ele é construído na mídia tradicional, com certos elementos de racionalidade, existe o fato, não é? O fato não é propriamente escandaloso mas o que é escandaloso é a construção midiática de tipo ideal, que é então, violado por aquele fato existe essa construção da mídia pra construir, pra identificar, a a narrativa do escândalo, então o exemplo, disso é o escândalo do Bill Clinton né, que também teve impacto político importante, que diz respeito a uma relação sexual, que é aspecto privado não é propriamente o, não foi propriamente o cerne da questão explorado pela imprensa, o que foi explorado pela imprensa foi o tipo, ideal da dignidade do presidente que não poderia mentir pro povo americano. O grande problema ali tinha a ver com, e a questão que foi pro tribunal, foi se ele teria mentido ou não uma relação sexual, que seria o fato, que talvez provocasse, uma reação psicológica negativa, virou em torno do presidente mentir ou não. Então o escândalo segundo o errar não é o fato, e também não é a reação psicológica de repulsa, que toda a construção midiática traz com a violação. Essa reação psicológica de repulsa, o errat chama de ultraje, né, e eu queria trabalhar essa noção de ultraje, agora no próximo slide. Ultraje que é a reação psicológica de repulsa a determinado fato a determinado episódio. Quando nós olhamos a catequese do Vaticano sobre o sentido de escândalo, o sentido é totalmente diferente do uso atual da palavra. Escândalo na catequese do Vaticano, escandalizar significa levar alguém vulnerável ao pecado, A palavra grega, na verdade a tradução grega do termo hebraico pra escândalo escândalo. Ela significa pedra de tropeço. Então escandalizar encontrar alguém vulnerável pra colocar uma pedra fazendo com que ele tropece. E essa é uma noção muito interessante pra pensar, as mídias atuais, as novas mídias, vamos trocar o slide, né? Porque, quando a gente tem, fato que é explorado nas mídias atuais, no normalmente você já não tem mais espaço de uma mídia centralizada que constrói no na esfera pública no discurso público, debate racional em em torno da dignidade do presidente ou seja lá qual foi o tipo ideal construído. É uma discussão, que toma esse sentido de ultraje são pequenas ultrages, que vão ocorrer num espaço privado das relações, entre os grupos entre os amigos entre, os familiares, não é, com relação ao fato o fato passa a ser fato ultrajante E0EA tônica está na relação psicológica negativa que ela provoca, né? Existe uma outra alegoria na na obra dos irmãos Kramasov que é muito interessante, que tem esse sentido de ultraje, além do tema geral dessa, da ideia do Parrigídio, que é a morte do padre Zózima, né do monge Zózima na verdade. O 0 monge Zózima tinha uma uma crença no povo russo em que, aqueles que são santos e tem a alma pura, o seu corpo não se deteriora depois da morte. E o Monges Osima que era adorado pela comunidade era ícone, ele durante o seu velório começa a exalar cheiro pútrido. Né? O seu admirador que é o herói da obra o Alioxa fica desesperado correndo pelos corredores, e ouvindo as maledicências, que acontecem ali nos meandros. E não consegue conter aquilo não consegue ter a menor forma de reação, EAEE nesse episódio se mostra como ícone é completamente destruído pelas maledicências. E é com isso que nós estamos lidando quando nós olhamos pra pra pras novas mídias, é o escândalo nesse sentido de ultragem comunicações ultrajantes que abordam o tema, e são mais difíceis de detectar na esfera pública, né? A gente tem recursos hoje como a Heloísa colocou de tentar, desmistificar desmistificar certos fatos mas o problema, é que, não temos debate público racional sobre isso é o ultraje, são as reações psicológicas negativas, que ocorrem e que vão se proliferando como o cheiro puto hidro que se espalha pelos corredores, e eu tenho uma dificuldade muito grande de controlar. Então vamos pro pro próximo slide. E, onde a inteligência artificial atua? Em dois momentos. Primeiro, como uma ferramenta que é capaz de detectar, como a Heloísa disse, o efeito está naqueles que já têm uma propensão psicológica por razões ideológicas et cétera, o efeito de notícias falsas né? Mas, esse problema já existe nas na atualmente independente da inter mente da inteligência artificial, a inteligência artificial agrave e traz elemento novo importante, primeiro a inteligência artificial detecta os vulneráveis, né no direcionamento de conteúdo você tem, inteligência artificial por trás traçando perfis, perfis e detectando quem está propenso a, mudar ou ter o seu juízo alterado, por conta de conteúdo enganoso. E por outro lado, diferentemente das fake news, a a inteligência artificial com as deepfakes, com alteração de conteúdo de voz, ou imagem de candidato, ela traz algo novo como elemento de prove convicção. Que é não só a confiança que nós temos num terceiro num veículo de reputação, mas é o testemunho ocular, nada mais forte do que o testemunho ocular. Eu não acredito naquilo que eu ouvi de veículo de comunicação ou de outro, Eu acredito no que eu vi. E isso traz uma diferença importante. Então, quando nós pensamos em regular o uso da inteligência artificial, nas eleições, são essas as preocupações. A preocupação não está com o escândalo no sentido tradicional da mídia tradicional mas com o ultraje a proliferação do ultraje dessas reações psicológicas, numa velocidade muito grande em que, eu tenho de lado, o uso da inteligência artificial pro direcionamento encontro da daqueles vulneráveis, e outro, a possibilidade de criar uma grande pedra de com de de tropeço, né? Forjar determinado conteúdo que gera testemunho ocular praticamente. Não é? E aí eu gostaria de pensar nessas noções num episódio recente envolvendo a deputada Tábata Amoral précandidata, ali, às eleições municipais em São Paulo, né? Todos devem conhecer esse episódio que inclusive já se judicializou, em que a Tábata Amaral reagindo à provocação do, précandidato Ricardo Nunes, chamoua de Barbie, ela então o chama de quem, porque ninguém o conhece todo mundo pergunta quem, segundo a comunicação ou a a reação da campanha que teve tom humorístico. E pra ilustrar, ela utilizou deepfake, né? A campanha alterou a imagem do prefeito como se ele fosse o personagem Ken, o boneco do do filme. Será que aqui nós estamos diante de uma tentativa de enganar o eleitor vulnerável para leválo a erro de julgamento? Será que o objetivo é efetivamente fazer com que eleitor acredite que o candidato Ricardo Nunes é boneco, é personagem desse filme? É claro que não. Então nós temos que olhar exatamente pra qual o problema, o problema não é usar a tecnologia e produzir problema está no resultado, está em buscar essa possibilidade de encontrar indivíduos vulneráveis pra alterar o julgamento, e se utilizar da tecnologia, para provocar o equívoco, pra provocar esse falso testemunho ocular, e mudar uma opinião, né? De uma forma generalizada e pulverizada, pelas novas mídias sociais, né? Tanto que, é tão estranho porque, a deputada voltou atrás, e então colocou uma foto só do Ricardo Nunes sobre a imagem, né? Só diminuiu a qualidade mas a ideia é a mesma, de reagir de uma forma humorística, a uma provocação que na verdade contribui pro debate, na verdade o Ricardo Nunes estaria insinuando que ela não teria experiência, o ela ali joga a discussão pro debate sobre, qual é a popularidade desse prefeito, né? Tudo faz parte do jogo das opiniões e do debate que é salutar pro processo democrático. Então, pra finalizar, olhando a as a regulação da, desculpe, está em inglês, pra olhando a regulação do Tribunal Superior Eleitoral, a gente vê ali a necessidade de interpretar com cautela, né? A proibição de uso do deepfake, ele está ligado, a usos que possam provocar desinformação, e que tenham efeito capaz de alterar, o resultado. Então levando isso pra essa noção de, ultraje e de escândalo, nesse novo sentido, nós estamos preocupados com aquele uso desonesto que ao né de que visa a enganar, e que também tem a possibilidade de. Claramente não é o caso, dessa desse episódio com a a Tábata Amaral, Mas interpretar com cuidado e olhando o que nossa preocupação está com esse objetivo de provocar esses pequenos e proliferados ultrages, nós temos que levar em consideração que diversos usos dos deepfakes são benéficos, não é? Então, usos pra reduzir custo de campanha, em que eu uso o mesmo vídeo, pra produzir diferentes discursos e diferentes de conteúdos, usando inteligência artificial sem que eu tenha todo o custo de produzir cada vídeo pra cada pra cada público, né? Como principalmente eleições municipais existem muitas muitas diferenças entre financiamento de campanha, o uso de ar, equilibra o campo de disputa, e é benéfico ao processo eleitoral. Podem existir determinados usos, em que, vamos imaginar candidato com dislexia, né com gagueira, eu vou usar sistema pra modular o meu discurso, deixandoo mais contínuo, isso facilita contra a compreensão dos eleitores sobre o meu conteúdo que eu quero transmitir como candidato. Esses são os desonestos nesse sentido de proliferar ultrajes? É claro que não, né? Então, ao pensar em regulação, nós temos que, ter todo o cuidado ao, estipular proibições pra que elas não sejam sobre inclusivas. E quando no contexto de uso de IA nas eleições nós estamos preocupados com essa capacidade da IA em encontrar os vulneráveis e a capacidade da IA de provocar falsos testemunhos oculares, que podem, e que tenham não só a intenção de enganar, como potencial, não o potencial de enganar de fato, o potencial de provocar uma alteração no resultado das eleições. Então é isso obrigado.",
      "speaker": {
        "name": "Juliano Maranhão",
        "position": "Prof. Dr. USP e Instituto Lawgorithm"
      }
    },
    {
      "id": 4104306,
      "start_time": 1715250371,
      "duration": 10,
      "transcription": "Professor Juliano Maranhão, eu passo agora a palavra ao Alisson Posta, professor do IBMEC, pra fazer suas considerações. Bom dia.",
      "summary": " Mestre de Cerimônias passa a palavra para o professor Alisson Posta do IBMEC para suas considerações.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104300,
      "start_time": 1715250381,
      "duration": 5,
      "transcription": "",
      "speaker": {
        "name": "Alisson Pessoa",
        "position": "Professor IBMEC"
      }
    },
    {
      "id": 4104296,
      "start_time": 1715250386,
      "duration": 9,
      "transcription": "Aqui a presença na casa do deputado Júlio Lopes e agradecer a presença. Muito obrigado deputado.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104316,
      "start_time": 1715250395,
      "duration": 852,
      "transcription": "Primeiramente quero parabenizar a organização do evento ao Partido Solidariedade. Uma honra muito grande estar nessa mesa com a doutora Heloísa, com o doutor Juliano Maranhão. Também quero saudar o deputado Júlio Lopes, com quem tenho a honra de trabalhar na Frente Parlamentar do setor de Serviços, na questão justamente de do, do no auxílio, a atividade legislativa no que tange novas tecnologias. Quero notar também a presença da doutora Tainá Junkillium, uma grande amiga e uma das maiores referências na área hoje no Brasil, e a minha turma de primeiro semestre do IBMEC que veio em peso aqui é é observar pouco as dinâmicas do Congresso Nacional. Pois bem, hoje em dia a questão da da IA dos usos de inteligência artificial na questão eleitoral, elas estão como bem notado pelo pelo pelos palestrantes antes de mim, elas estão muito focadas na questão da IA generativa. E não não seria diferente considerando que desde que o ChatGPT há dois anos atrás ele levou pra sociedade em geral, a experiência de poder, fazer uso de uma tecnologia avançada sem conhecimento específico e complexo de programação enfim, causou então essa comoção a nível mundial e desde então, desde que o ChatGPT chegou pro público, a gente tem visto não só uma evolução muito rápida na nos mas também as preocupações com a regulamentação. E aqui, a gente tem tido vários, vários seminários, palestras, enfim, tratando justamente como o TSE regulou na resolução da do início desse ano a agenerativa, do outro lado as discussões sobre como que o PL vinte e três três oito está trazendo mecanismos de regulação, não só pra iagenrativa, mas também pra as estruturas de governança e gerenciamento de risco. E, eu eu quero focar aqui num ponto que a doutora Heloísa ela passou brevemente, mas que me chamou muito atenção na resolução desse ano do TSE, que é o fato que, enquanto a os pontos sobre a generativa da resolução no no artigo dez, eles foram pontos, enfim, como eu vi várias pessoas falando, o TSE fez o que deu pra fazer, focou em em mecanismo de identificação algumas distribuições e responsabilidade. Mas uma das grandes críticas que que tem se feito em relação a isso é olha, o TSE ele ele fez o que deu mas no ponto de vista da da fiscalização vai ser muito difícil Porque tu demanda que do outro lado é exista ali uma boafé de fazer efetivamente a identificação. E dos problemas que hoje que a os partidos eu tenho trabalhado com alguns partidos siglas nacionais aqui em Brasília, em relação porque as siglas estão preocupadas, não são só a as estruturas oficiais das campanhas é que agem no período eleitoral nós temos as estruturas não oficiais e a própria movimentação orgânica os apoios orgânicos Principalmente quando a gente fala é de municípios maiores e capitais. Porque muitas vezes é esse uso da IA é que choca e tenta fazer causar uma disrupção no processo eleitoral, ele é uso que vai partir não de pessoas de boafé, mas de pessoas de má fé e que estão nas estruturas não orgânicas da campanha. Então as siglas nacionais elas já estão preocupadas que entra nesse contexto do limite do quanto o TSE vai conseguir em relação a isso. E aí me chamou atenção justamente que, nessa mesma resolução, de uma maneira muito aprofundada, o 0 TSE debruçou sobre a proteção de dados, e isso é muito interessante por vários motivos. Primeiro, em dois mil e vinte e o TSE e a ANPD fizeram guia sobre a questão da produção de dados no no contexto eleitoral, e causou uma nova, acabou gerando uma resolução que modificava a vinte e três seiscentos e dez com elementos de observância da LGPD, mas eram elementos ainda muito genéricos coisas do tipo olha, no uso de base de dados tem que ser observar LGPD ainda eram muito superficiais. Dois mil e vinte e dois trabalhei em algumas campanhas deputado deputado federal senado e governo estadual do ponto de vista da LGPD, da governança na questão de dados. Ainda não só as equipes das campanhas como também as empresas do marketing político, ainda muito tímidas na questão de se preparar pra observar esses desafios. Desde então nós tivemos, uma sanção da NPD pra pra empresas pra uma pra uma microempresa que teve o contexto eleitoral, mas foi uma sanção muito criticada pela maneira que foi feita e muito tímida. Foi uma uma multa acho que de quatorze mil reais, não fala falha a memória. O TSE chegou a fazer menções a LGPD e as resoluções mas também é de uma maneira muito tímida e agora quando o TSE resolve regular a inteligência artificial generativa, ela traz nos artigos 33 b, 36 c e trinta e seis d, regulamentações bem aprofundadas sobre proteção de dados e até eu em alguns pontos eu até me questiono assim se se não houve até uma invasão de competências em algum ponto em relação a NPD, mas eles aprofundaram muito e questionando o porquê disso. Eu chego a uma conclusão minha é que. Enquanto o TSE vai ter dificuldades com a fiscalização da da questão de inteligência artificial do uso de inteligência artificial generativa na questão de proteção de dados não. No momento que eles estabelecem modificadores pras estruturas e governança de proteção de dados dentro das campanhas numa maneira muito aprofundada e muitas delas demandando a geração de evidências, como por exemplo relatórios de impacto, facilita o trabalho do TSE em realizar fiscalização sobre o uso de inteligência artificial, mas não as generativas. E outro tipo de inteligência artificial que a doutora Heloísa também comentou, eu até fiquei preocupado quando começou a falar porque eu pensei meu Deus vai começar a falar tudo aquilo que me preparei pra falar. Que são esses usos não de agenerativa pra influenciar o discurso AAA campanha, mas a os usos de inteligência artificial pra entender o eleitorado e o que eu tenho visto hoje alguns partidos já estão olhando pra esses usos de inteligência artificial que são mais complexos em que envolve a coleta de grandes bases de dados, mecanismos de web scraping em tempo real de impressões nas redes sociais E a utilização de inteligência artificial pra ter aí uma capilaridade muito maior, não só no feedback das estratégias da campanha, porque até então a leitura sobre o atual estado da campanha, ela ainda fica muito ela ainda está muito vinculada com as pesquisas e as pesquisas elas acontecem tempo em tempo, elas têm regras muito específicas, então, o uso de inteligência artificial aliado a impressões a leitura de impressões na redes sociais, elas permitem com que os partidos e os candidatos eles consigam ter uma adaptação muito melhor nas estratégias das campanhas, ver aquilo que está funcionando, não que não está funcionando. Permite também identificar áreas do discurso eleitoral, onde o candidato pode focar e ter uma efetividade melhor. E esses são usos completamente legítimos, que porque a gente está acostumado a olhar muito sobre a do ponto de vista os problemas os riscos etcétera e realmente existem problemas e existem riscos a doutora Heloísa mencionou o caso quimbridge analítica. Agora, nesse nesse contexto do atual estado da arte da inteligência artificial, a gente vê esses usos cada vez mais sofisticados e que, por mais que o doutor Juliano Manoel ele mencionou que olha no contexto de uso de IA generativas, nós temos a IA como uma ferramenta que pode ajudar a trazer equilíbrio maior as as disputas, mas de outro lado esses usos mais complexos eles podem acabar gerando aprofundando o abismo das diferenças e enfim a falta de equidade nas questões das estratégias eleitorais, porque esses são usos muito mais sofisticados, muitos e muito mais caros. Então nós temos aqui essa balança, em que de lado nós temos inteligência artificial que como uma ajuda, e outra inteligência artificial que ali acaba gerando desigualdades muito maiores no pleito. E aqui, nos últimos minutos do do meu tempo de fala eu quero passar bem sucintamente sobre pontos dessa resolução que tem, a a influência pra mim tem muito essa tônica de olha, o TSE ter ferramentas pra pra fazer a fiscalização e a sanção do ponto de vista da proteção de dados no nesse contexto tecnológico de inteligências artificiais. O primeiro pra mim que que faz muito, que deixa muito claro isso é que o artigo trinta e três d ele fala que nos cargos, nas eleições de cargos pra presidente da república, governador, senador, prefeitos de capitais, ou seja, já valendo pra essas eleições, a Justiça Eleitoral vai poder determinar a elaboração de relatório de a proteção de dados nos casos em que o tratamento apresenta alto risco. E aí eles trazem considerações de alto risco. Então larga escala como considerado no mínimo dez por cento do eleitorado apto da da circunscrição que está abrangido na no alcance do candidato, e em outro, que envolva o uso de dados pessoais sensíveis ou de tecnologias inovadoras ou emergentes para perfilamento de eleitores, e eleitoras com vistas ao de propaganda eleitoral e da comunicação da campanha. Isso pra mim, esse artigo ele dá muito essa tônica ele entrega que olha, o TSE ele enxerga a proteção de dados como o caminho da que vai gerar evidências que vai permitir uma efetividade da fiscalização eleitoral muito mais do que só gerar obrigações pras pra todos os agentes envolvidos na campanha que dependem da boafé deles de cumprir ou não de gerar as marcas da água de trazer a transparência de que existe a a inteligência artificial mecanismo de inteligência artificial. Então é isso a minha fala ela ela focou justamente nesse nesse contexto de que não tem sido tão na resolução de dois mil e vinte na resolução de dois mil e vinte e em contexto em que, querendo ou não, a autoridade nacional de produção de dados hoje na parte sancionatória e fiscalizatória ela ainda está muito tímida. Então por que o TSE fez isso? Quando eu começo a me que quando eu comecei a me questionar sobre essas mudanças, e pegando textos e elementos de outros profissionais da área, falando sobre as dificuldades que o TSE vai ter mesmo com o que ele conseguiu construir em relação à IA generativa, me parece muito claro que a guerra do TSE na questão de uso de tecnologias que visam trazer uma discussão negativa pro processo eleitoral não vai se dar exatamente no na Então essas são as minhas considerações, eu Então essas são as minhas considerações eu agradeço aqui a presença e atenção de todos muito obrigado.",
      "summary": " Professor IBMEC discutiu uso de IA no eleitoral, destacando:",
      "speaker": {
        "name": "Alisson Pessoa",
        "position": "Professor IBMEC"
      }
    },
    {
      "id": 4104303,
      "start_time": 1715251247,
      "duration": 16,
      "transcription": "Agradecer as considerações do Alisson Pozza e passamos agora a palavra ao Caio Saja, que vai fazer diálogo entre os sobre o que foi feito até o trabalho realizado até o momento.",
      "summary": " Mestre de Cerimônias agradece Alisson Pozza e entrega a palavra a Caio Saja para discutir trabalho até o momento.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104313,
      "start_time": 1715251263,
      "duration": 270,
      "transcription": "Todas e todos, agradeço aqui a fala de todos os painelistas, contribuições muito boas e que, ressaltam a complexidade realmente do tema da inteligência artificial, né, a gente precisa evitar visões simplistas ou alarmistas, precisamos sempre ter em mente também os benefícios da tecnologia, e além disso como acho que todos mencionaram aqui, a gente tem falado muito de deepfake ultimamente porque é o risco mais, digamos assim, aparente que a gente vê mais na mídia, relacionado a a eleições, né? Mas existe também, além da iagenerativa que está na moda, aí a preditiva, né, que é o que está por trás por exemplo dos das redes sociais, é justamente o que permite a detecção dos vulneráveis como professor Juliano falou e também o micro direcionamento de informações e propaganda, como o professor Alisson destacou. Então eu queria aqui explorar com os três panelistas outro, assim, outro tipo de risco que alguns estudiosos da Inteligência Artificial, de ética na Inteligência Artificial de fora do Brasil também tem tem comentado, que é não exatamente o risco da IA pra pras eleições, mas pra democracia como todo. Como a inteligência artificial é capaz de afetar a liberdade de expressão, que é direito fundamental, tá no artigo quinto da nossa constituição, de forma que, enfim, todo esse debate sobre regulação da IA não pode perder de vista também a preservação da liberdade de expressão. No caso, o risco que a IA pode apresentar a liberdade de expressão, e eu queria ver se os painelistas concordam, está mais no campo da IA preditiva, porque como as redes sociais, o modelo de negócio das redes sociais que hoje são o ambiente onde maior parte das pessoas formam sua opinião, são movidos pela chamada economia da atenção, que a estratégia mais efetiva é sempre direcionar ele informações que ele considera positivas, ou seja, no caso da da das eleições, isso acaba por gerar o que se chama de câmara de eco, quer dizer, a a pessoa que tem determinado viés político político ideológico acaba vendo sempre as informações que são do agrado dela, de forma que isso acabaria por, assim, acabaria por piorar o problema da da polarização, Então eu queria ver a opinião dos dos painelistas, se eles acham que efetivamente a IA pode representar problema à liberdade de expressão nesse sentido, na medida em que ela cria maior ambiente de polarização, e se eles concordam de que forma a gente deveria endereçar isso, se as resoluções do TSE já lidam com isso de alguma forma, se a gente deveria lidar com isso por meio de do PL de inteligência artificial ou do PL das fake news, como a gente deveria lidar com esse com esse tipo de risco da IA, a liberdade de expressão. Não sei se alguém quer falar primeiro ou se a gente segue a ordem. Bom, obrigada Caio pela pergunta, é uma pergunta",
      "summary": " USP aborda impacto de Inteligência Artificial (IA) na liberdade de expressão, especificamente na forma como a IA preditiva pode reforçar polarização através da \"economia da atenção\" nas redes sociais. Discutindo possíveis abordagens para abordar esse desafio, menciona TSE, Plano de Lei de Inteligência Artificial e Plano de Lei de Fake News como possíveis ferramentas.",
      "speaker": {
        "name": "Caio Missagia",
        "position": "USP"
      }
    },
    {
      "id": 4104324,
      "start_time": 1715251533,
      "duration": 217,
      "transcription": "Interessante, eu acho que tem vários aspectos, enfim, não tem uma resposta, eu não tenho uma resposta definida pra isso, mas eu acho que talvez seja interessante explorar pouco o que é liberdade de expressão e que a gente também entende por liberdade de expressão. Ele é direito humano universal que vai aparecer nas declarações de direitos humanos, mas a concepção de liberdade e expressão ela acaba mudando muito em determinados contextos, né. A gente tem a concepção, por exemplo, americana de liberdade de expressão que ela é uma concepção bastante radical contra qualquer tipo de interferência, mas quando a gente olha pro Brasil, a nossa concepção de liberdade de expressão ela vai ser diferente, né. E a gente gosta, né, falando enfim desde a Internet Labs de entender liberdade de expressão, a partir também de uma perspectiva de ambientes seguros e íntegros onde as pessoas e diversos onde as pessoas possam de fato falar, né. A liberdade de expressão é essencial pra pro debate público e pra uma esfera pública e política saudável. E o acesso à informação também é na medida em que ele também é muito ligado à própria ideia de liberdade de expressão. E quando a gente pensa em ambientes digitais ou quando a gente pensa no debate público de uma forma geral, se a gente tem ambientes que silenciam determinadas pessoas ou determinados grupos, por violência, por falta de segurança, etcétera, a gente tem aí algum risco de fato a liberdade de expressão, então acho que esse é o primeiro passo né, como a gente olha pra liberdade de expressão. Mas quando a gente pensa em câmeras de eco e em redes sociais, eu acho que tem uma coisa que é, quando a gente pensa em polarização e essa ideia que existe de de câmara de eco, a gente pode cair muito, numa armadilha de pensar que antes da internet ou das redes sociais as pessoas tinham contato com todo e qualquer tipo de formação diversa, né? A ideia de afinidade de opiniões e de ideologias, ou essa ideia de câmara de ego né, como a gente tem, ela sempre foi presente. É óbvio que a forma de funcionamento mais personalizada das redes sociais ela tem uma certa afinidade aí com essa tendência que a gente já tinha na comunicação política entre as pessoas. Então eu acho que isso é uma coisa, né, e daí eu acho que quando a gente está olhando pro funcionamento desses, dessas, enfim plataformas e como esse conteúdo é distribuído, eu eu acho difícil ver risco direto à liberdade de expressão quando a gente pensa nessa ideia de de polarização, porque eu acho que, enfim, se se não existe de fato, se você tem, muitas aspas né, essas câmeras de eco mas você não tem violência, é espaço seguro, de certa forma, eu acho que o risco liberdade de expressão ele acaba sendo muito subjetivo aí porque daí você partiria de pressuposto de que existiria direito de alcance, ou de que as pessoas tivessem alcance nas plataformas o tempo todo, eu acho que esse é debate pouco mais complicado, né. Então eu, enfim, eu acho pouco difícil responder isso de uma forma definitiva mas eu acho que são essas algumas considerações sobre como a gente enxerga essa personalização e como a gente enxerga a liberdade",
      "summary": " Dra. InternetLab debatéu liberdade de expressão, sua importância no público e contextos variados; liberdade necessita de ambientes seguros, inclusivos e acesso à informação; em ambientes digitais, silenciar pessoas ou grupos ameaça liberdade; polarização online dificulta definir risco à liberdade de expressão, embora redes sociais possam reforçar afinidades políticas.",
      "speaker": {
        "name": "Heloísa Massaro",
        "position": "Dra. InternetLab"
      }
    },
    {
      "id": 4104297,
      "start_time": 1715251750,
      "duration": 235,
      "transcription": "",
      "speaker": {
        "name": "Juliano Maranhão",
        "position": "Prof. Dr. USP e Instituto Lawgorithm"
      }
    },
    {
      "id": 4104298,
      "start_time": 1715251985,
      "duration": 259,
      "transcription": "",
      "speaker": {
        "name": "Alisson Pessoa",
        "position": "Professor IBMEC"
      }
    },
    {
      "id": 4104315,
      "start_time": 1715252244,
      "duration": 126,
      "transcription": "Eu acho que é isso, agradeço a resposta. Vamos pro próximo painel, né? Eu queria então agradecer os membros da primeira mesa, Professor Juliano Maranhão, Alisson Poça, o Caio, a Heloísa e o Caio pode ficar na mesa que vai fazer o papel similar na no próximo painel. Eu queria chamar então o próximo o nosso próximo painel aqui, que vai ser a Tainá Junkillo, professora da UNB e DDP, o professor doutor Daniel Vila Nova, da UNB e DDP, E o Professor Doutor Lucas Amato da Faculdade de Direito da USP. Senhor senhor senhoras, por favor, se incomoda aí na mesa? Eu passo então agora a palavra à professora Tainá Junquilho pra fazer suas considerações. Eu peço aos palestrantes que informem oralmente a mudança de slide, pra pra que isso possa acontecer de maneira tranquila. Muito obrigado. Você pergunta se eles receberam a última versão, falou? Isso. A professora Tainá indaga audiovisual se foi feita a troca do arquivo de apresentação dela. Acredito que sim, né? Já foi enviada há uns quinze minutos atrás.",
      "summary": " Mestre de Cerimônias anuncia próximo painel com Tainá Junquilho, Daniel Vila Nova e Lucas Amato. Agora para considerações da professora Tainá. Pedido de informar mudança de slide e confirmação de recebimento de arquivo de apresentação atualizado por audiovisual.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104339,
      "start_time": 1715252370,
      "duration": 964,
      "transcription": "Bom, bom dia a todos e todas, é uma alegria estar aqui na casa, a convite do professor Ricardo, do Caio, descobri que o Caio é capixaba, parabenizo também a solidariedade, pela iniciativa importante num ano super relevante, de trazer pra casa do povo, esse tipo de discussão e abrir inclusive online também as discussões. Então, é é o momento da gente discutir isso, e a minha fala aqui vai ser mais voltada a como regular a inteligência artificial em âmbito eleitoral focando pouquinho na discussão atual que a gente está tendo do pl 2338 o que a gente chama de substitutivo do substitutivo que inclusive hoje é o último dia da da abertura para consulta pública, né? Pode passar por favor bom a gente tem vários usos da Inteligência Artificial no contexto eleitoral mas mais recentemente, a inteligência, sem dúvida a inteligência artificial generativa, ela salta aos olhos nossos e chama a atenção de toda a comunidade jurídica legislativa, porque ela traz uma série de de possibilidades de uso que acabam nos assustando né É porque ela é capaz de gerar textos para principalmente no âmbito eleitoral né ela gera textos para discursos para publicação na internet né, então você pode, a partir de simples comando, gerar discurso político uma publicação na internet tanto de imagem quanto de texto você também pode gerar conteúdo sintético que é assim tem sido assim chamado pela pela regulação da propaganda eleitoral que depois eu vou falar pouquinho mais para frente da do TSE do Tribunal Superior Eleitoral a gente tem a geração de imagem texto e voz e chatbots de interação também com os eleitores entre os tanto partidos políticos e eleitores quanto também é entre os próprios candidatos né a campanha do candidato e os eleitores pode passar por favor Mas surgem alguns desafios, então a gente tem uma série de bons usos e possibilidades, de fato, o maior ganho principalmente da Inteligência Artificial generativa é o ganho de produtividade que é o sonho de todo mundo né a partir de comando de simples que a gente chama de pronto se você criar texto enorme você criar consegue disseminar aquele conteúdo de forma muito mais rápida porque a gente ainda não tem para quem acredita em Deus só Deus tenha o poder da onipresença né? Então quando você produz uma imagem de candidato ou uma voz, isso permite que ele esteja, adquira uma uma atributo que é quase que, dos deuses, né, ou de Deus, que é a onipresença, ele pode estar em vários lugares ao mesmo tempo, né? E isso claro sem dúvidas é pode ser bastante interessante, enfim, gerar realmente conteúdo relevante, enfim, gerar realmente conteúdo relevante inclusive, mas traz uma série de riscos que a gente já tem pesquisado e é por isso que a gente fala numa, que a gente vive uma fase de não mais se regular, mas como regular a inteligência artificial. Então especificamente no contexto eleitoral quais são esses desafios, né? A possibilidade de desinformação por meio desses desses dessa yaginerativa principalmente né que ela pode produzir mesmo que às vezes notoriamente algo que é produzido pela inteligência artificial e que muitas vezes não vá a princípio seja mais pra digamos assim, brincar com outro candidato, né, como foi o exemplo ali da Tábata Amaral com quem, mas pode causar também uma série de desinformações, como no caso por exemplo da do contexto eleitoral que passou no passado a Argentina e que foi utilizado aí para produzir desinformação é também pode ser utilizado para produzir discurso de ódio e reproduzir esse discurso de ódio, é possível que a inteligência artificial aumente a polarização que já está bem grande né no no mundo inteiro A inteligência artificial generativa ela também pode produzir discursos falsos, então é muito relevante que a gente sabendo dos benefícios que a inteligência artificial possa trazer, inclusive quem né, assessora campanhas políticas em termos de marketing, avise AAA as campanhas e aos políticos que estão utilizando inteligência artificial por exemplo pra produção de discursos, que aquela inteligência artificial pode ter discurso que tem sido chamado académicamente de alucinado ou seja ela pode trazer conteúdo que não condiz de fato com a realidade pode trazer dados inventados eventualmente né E, para além disso, se você é uma campanha que usa inteligência artificial, algum desses aplicativos, numa versão que por exemplo não é paga uma versão aberta é o uso dos dados eventualmente é para onde aqueles eventualmente é para onde aqueles dados que estão sendo jogados ali naquele aplicativo vão ser usados Então tem que ter uma cuidado extremo e relevante da campanha e do candidato com os aplicativos que são usados inclusive pra inteligência, no caso de inteligência degenerativa pra geração de conteúdo, pode passar. Por favor, obrigada. E aí a gente tem diante desses desafios éticos, primeiro o fato de que a inteligência artificial, como o Kate Crowford diz na sua obra, né, Atlas of off e a ida o atlas da Inteligência Artificial ela diz que a inteligência artificial não é nem artificial nem inteligente não é inteligente nos termos da inteligência humana como a gente concebe historicamente nem quando da quando dá produção desses modelos desenvolvimento e até colocação no mercado, né? Então por isso ela se diz que ela nem é artificial nem inteligente como a gente entende né e há uma série de críticas que eu não vou entrar agora a esse inclusive essa antropomorfização do conceito de inteligência artificial justamente porque ela nem é artificial nem é inteligente como a gente consegue né? No entanto hoje desses desafios que são conhecidos cientificamente já, a gente tem o que Luciano Floride, que é dos filósofos da atualidade mais citados porque ele estuda as consequências da sociedade na informação, chama de igreja dos céticos, que aquele pessoal que acha também que a inteligência artificial vai estar provavelmente muito perto de dominar o mundo e a gente tem expoentes até com bestsellers né, como por exemplo e o Val Noah Harari, que fala que a inteligência artificial muito em breve vai ser criado uma nova espécie humana, que vai ser o homozumbi que é aquele que diante do de toda a inteligência artificial, ele é substituído e fica aí perambulando sem emprego, né, substituído de fato pela máquina, então ele é totalmente apocalíptico. Não é o caso, né, hoje em dia a gente tem riscos concreto, muito mais concretos do que esse, né, do ex máquina, da de uma inteligência artificial robô e antropomórfica que vai destruir a humanidade, existem riscos já concretos e por isso, entendo em vista esses riscos concretos é que a gente fala numa promoção de valores no como regular, pode passar pro próximo por favor? Então a gente passa por esse momento mundial em relação à inteligência artificial que é não mais se, mas como regular, então num primeiro momento a gente traz os princípios mundialmente né da bioética, embora a gente tem essa hype toda que chegou principalmente no final de dois mil e vinte e dois com o lançamento do ChatGPT na sua terceira versão, já tem tempo que a gente está discutindo questão de regulação da inteligência artificial, né, então primeiro a gente traz os princípios da bioética, depois a gente atingir certo consenso mundial existem vários estudos do Burkman Clin Center por exemplo que traz ali consenso mundial acerca de princípios pra se produzir uma inteligência discriminatória e a transparente e a responsável. Você tem momento também de países fazendo as suas estratégias internamente, pra de como vamos produzir essa inteligência artificial pra também garantir uma soberania nacional e agora a gente está vivendo esse momento do não mais ser mas como regular e aí pipocando projetos de lei pelo mundo inteiro pode passar por favor no Brasil é resumidamente né porque também não quero me estender além do meu tempo a gente tem a estratégia brasileira de inteligência artificial, que sofreu uma série de críticas porque ela traz uma ela ela não traz uma agenda específica para o Brasil ela é muito principio lógica então ela fala precisamos de investimentos em Inteligência Artificial sim mas como como que a gente vai investir na Inteligência Artificial esse mesmo momento tanto da Estratégia quanto da regulação né, como que a gente vai especificar uma IA por exemplo não discriminatória. Então depois da Ebia, da Ebia que está sendo atualizada inclusive justamente porque não traz muita coisa estratégica, no fim das contas, vem o a proposta legislativa a daqui da Câmara dos Deputados, vinte e vinte, mais que foi, embora tenha havido aí algumas audiências públicas ela foi aprovada em regime de urgência e quando ela chega no senado depois dessa dessa aprovação em regime de urgência ela recebe muitas críticas porque não se aprova né uma matéria tão complexa em regime de urgência então quando ela chega no senado esse texto do PL 2120, é montada então é criada uma comissão de dezoito juristas, professor Juliano Maranhão fez parte dessa comissão inclusive, que tava aqui no painel anterior e que apresentou no final do ano de dois mil e vinte e dois novo texto agora mais especificado. Entretanto entendeuse que precisavamse de novas discussões sobre esse texto e aí o senador Eduardo Gomes criou uma comissão temporária de inteligência artificial é para discutir PL que aí já virou o PL 23 38 que cujas as consultas públicas estão abertas agora até hoje, né, e provavelmente o Senador Eduardo Gomes também já está fazendo esforços para que provavelmente até o fim desse mês de maio a gente tem aí texto que vá pra agora emendas e e sofra todo o processo legislativo. Sofra não né porque coitado do pl passe pelo processo legislativo e a gente tem no Brasil momento que é além das eleições o fato de que a gente está num ano de liderança do g20 então todos os líderes tanto parlamentares quanto do executivo quanto do Judiciário estão pensando em questões e uma das questões em relação à liderança do G vinte que o Brasil quer deixar como legado é essa questão da regulação da inteligência artificial. Então a gente está, pode passar por favor, nesse momento exato em relação à regulação da inteligência artificial no Brasil. E no dia dezessete de abril o senador Eduardo Gomes apresentou então substitutivo do substitutivo. Por que substitutivo do substitutivo? Porque a comissão de juristas apresentou texto que era substitutiva ao PL vinte vinte e, a partir desse texto, a o Senador Eduardo Gomes então criada essa comissão temporária de senadores apresentou outro texto e aí eu peguei aqui para vocês darem uma olhada já que nós temos algumas horinhas ainda do dia para vocês enviarem as consultas as contribuições da consulta pública quem sabe alguém ainda tenha fôlego para enviar alguma coisa então eu peguei aqui em relação a esse texto o que que ele prevê sobre inteligência artificial e eleições especificamente então você tem a criação de sistema nacional de regulação e governança de Inteligência Artificial é essa então é uma esse substitutivo ele traz esses esse que está sendo chamado de Cia que é uma autoridade que se pretende articulador ela tem o papel de fiscalização de interoperabilidade legislativa. O uma interoperabilidade legislativa o que que cada setor já né eleitoral o setor da saúde o setor da da Inteligência Artificial Então ela tem esse papel de fiscalizador mas também de articulador é traz alguns instrumentos de fomento para além da sandbox regulatórias CIA no investimento em pesquisas brasileiras você tem o artigo segundo é inciso 16 que traz os fundamentos da Inteligência Artificial e deles é que a inteligência dos fundamentos é que a inteligência artificial seja utilizada para fortalecimento do processo democrático pode passar por favor a gente tem também a classificação e riscos né então esse esse",
      "summary": " Profª UNB e IDP discutiu regulamentação de IA em contexto eleitoral, destacando desafios como desinformação, ódio, polarização e alucinação. Eles abordaram igreja dos céticos, riscos concretos e ética. No Brasil, há ênfase em regulamentação de IA, com Senador Eduardo Gomes liderando esforços para texto final em maio.",
      "speaker": {
        "name": "Tainá Junquilho",
        "position": "Profa. UNB e IDP"
      }
    },
    {
      "id": 4104304,
      "start_time": 1715253334,
      "duration": 6,
      "transcription": "Desculpa professora Tainá, eu vou pedir pra senhora caminhar pra conclusão por causa do tempo?",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104320,
      "start_time": 1715253340,
      "duration": 119,
      "transcription": "Ah tá desculpa já tô terminando cinco minutos não dois então a gente tem é PL baseado em níveis de risco né E aí no artigo 15 você tem também considerado como nível de risco que o sistema possa impactar negativamente na integridade da informação é então esse também é considerado alto risco se o a inteligência artificial impactar na integridade da informação pode passar por favor traz algumas medidas de governança nesse sentido no artigo 19 como por exemplo quando a inteligência artificial gerar conteúdo sintético deve incluir considerando o estado da arte a a identificação pode passar por favor a gente tem a resolução do TSE que traz ali geração de textos para discursos como possível né Essa essa essa uso daí a generativa proíbe totalmente o uso de defeito e traz algumas possibilidades para geração de imagens som e voz e chatbots desde que seja para questões como por exemplo alteração da imagem melhoria na imagem criação de logomarca mas sempre colocando também a marca de que usou uma inteligência artificial E aí prometo que é o último slide algumas reflexões que ficam né que até foi colocado na mesa anterior a gente passa por momento em que de certo ceticismo de desconfiança com as imagens que são produzidas justamente porque muita coisa tem sido produzida pela inteligência artificial, então você fica sempre desconfiando. E também a falta, né, uma das conclusões é a falta de regulação, ela traz ali resoluções do judicialização sem uma sem uma uma concepção do que vamos seguir legislativamente quando o legislativo não atua o judiciário acaba atuando e soltando regulações como essa do TSE. Mas era isso que eu queria hoje falar aqui e fico à disposição. Obrigada. Obrigado.",
      "summary": " Profa. UNB e IDP abordou PL com riscos relacionados à integridade de informações, considerando alto risco quando IA impacta negativamente. No artigo 19, medidas de governança como identificação de conteúdo sintético e uso de marcação para IA em geração de texto, imagem, som, voz e chatbots são discutidas. Ela ressalta ceticismo e falta de regulação, citando resolução do TSE sobre geração de textos e uso de IA, e se mostra disponível para discussões adicionais.",
      "speaker": {
        "name": "Tainá Junquilho",
        "position": "Profa. UNB e IDP"
      }
    },
    {
      "id": 4104308,
      "start_time": 1715253459,
      "duration": 13,
      "transcription": "",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104323,
      "start_time": 1715253472,
      "duration": 1080,
      "transcription": "Obrigado, bom dia a todos e todas. Queria cumprimentar, agradecer especialmente a a Câmara dos Deputados, na pessoa do Misaja, pela organização, pelo convite para participar desse painel. E o tema do painel é como regular a inteligência artificial no âmbito eleitoral, Mas como dizia a professora Tainá, a pergunta de como a resposta a como regular a inteligência artificial no âmbito eleitoral, depende de uma pergunta anterior e das respostas que a gente deu à pergunta anterior que é, por que regular a inteligência artificial no âmbito eleitoral? E, a princípio, o objetivo seria garantir voto livre e informado nas condições atuais de de domínio das mídias digitais. Mas essa resposta enfrenta ceticismo, enfrenta ceticismo sobre por que ter normas jurídicas regulando esse tema, por que não seria melhor manter ambiente não regulado. E a resposta que a gente poderia dar AAA essa ausência de regulação, tem a ver com os riscos de uma ausência de regulação, que são riscos gerados por diversos atores, e esses riscos vão se retroalimentando e se magnificando riscos gerados pelos próprios usuários das tecnologias das e das plataformas, riscos gerados pelas empresas, e riscos gerados pelo estado, propriamente dito. Então se a gente pensar primeiro nos nos eleitores como consumidores e também como produtores e usuários das tecnologias associadas à inteligência artificial, e também associadas ao uso das plataformas digitais. O que a gente tem é o risco de de reforçar uma dinâmica de de linchamento, de autocensura, de distorção dessa informação que não é mais só consumida de maneira descentralizada, mas é produzida de maneira descentralizada pela popularização dessas dessas tecnologias da inteligência artificial generativa, a produção de textos, de áudio, de vídeo, que qualquer pode fazer, e isso influencia a percepção, a produção da realidade, por meio de uma comunicação que circula dessa maneira anárquica e e policêntrica, diferente do que era a comunicação produzida pelos meios tradicionais da mídia do século vinte, que era uma comunicação editorializada, produzida profissionalmente e consumida só de maneira massificada. Então se a gente deixa simplesmente esse estado de natureza virtual, em que todo mundo pode produzir o conteúdo que quiser, e disseminar esse conteúdo com uma com uma escala incontrolável, a gente acaba criando ambiente poluído, ambiente digital poluído que vai distorcer e vai conflagrar essa arena eleitoral, contradizendo aquele nosso objetivo que seria manter o voto livre e informado pra como base da democracia, não só da, se a gente pensar na democracia puramente eleitoral, mas se a gente pensar em possibilidades até de plebiscitos, de referendos, de aperfeiçoamentos da democracia, que eram vistos de maneira mais otimistas, mais otimista décadas atrás, e se pensava que a tecnologia ia facilitar que todo mundo participasse, desse sua opinião sobre qualquer tema de interesse público diretamente, e hoje em dia a gente tem uma grande ceticismo sobre o uso desses mecanismos de democracia participativa ou semirrepresententativa, porque se já é, se o ambiente já é poluído pra você escolher candidato, muito mais poluído se tornam pra você debater substantivamente os temas diretamente com com a população e colocar esses temas pra votação da população. Então a gente tem de lado esse perigo dum duma espécie de estado de natureza virtual pelo pelos próprios usuários, eleitores, cidadãos. E outro lado a gente tem os riscos gerados pelas empresas, que de lado produzem essa produzem a informação, e outro lado produzem as tecnologias que vão empacotar os usos, a disseminação dessa informação, EAE também por meio da da inteligência artificial preditiva vão influenciar a o consumo dessa informação, a compreensão vão enviesar a aceitação dessa dessa comunicação. Então essas empresas acabam atuando em todo em todo o espectro do do processo de produção e disseminação de uma de uma informação, de uma maneira diferente do que era a mídia tradicional, né? E essas empresas fazem isso obviamente com o objetivo de lucro, de monetização, o que não é problema em si mesmo porque é é é uma forma de estimular a inovação tecnológica. Mas o problema é que é mercado muito concentrado, em que a gente teria que pensar de lado em, nas questões concorrenciais e de democratizar esse mercado, de expandir a as possibilidades de de negócios no campo da geração das tecnologias de inteligência artificial. Mas de outro lado a gente também tem problema associado às empresas que é, o fato delas se esforçarem por autorregular o uso das suas próprias tecnologias. E essa autorregulação tem, pode ter dois riscos. Pode ser uma autorregulação simbólica, ineficaz, que é só escudo pra evitar que o estado, que alguma instituição estatal democrática, queira impor uma regra sobre aquele assunto, a empresa responde que ela já tem uma, já tem conjunto de regras que guia os seus próprios procedimentos de forma autorregulada, e de outro lado essa autorregulação pode ser autoritária, pode ser opaca, a gente pode não conhecer as regras e os procedimentos, as instâncias, as autoridades que realmente decidem se conteúdo vai ser autorizado a ser publicado ou se aquele conteúdo vai ser retirado de circulação. Então a gente tem esses esse impasse, a poluição do ambiente, porque todo mundo pode usar essas tecnologias pra produzir e disseminar informação, o problema econômico e da e da insuficiência da autorregulação pelas empresas privadas, e o terceiro risco que é o mais conhecido que é, o medo de que a intervenção estatal crie uma espécie de ministério da verdade que vai ficar e controlando cada conteúdo que vai ser produzido na opinião pública, monitorando a a opinião das pessoas. E qual que é a saída que a gente tem a a aos riscos gerados por esses vários atores? É de certa forma combinar esses vários atores num numa espécie de sistema aí de de freios e contrapesos na no no mundo digital, em que cada controla o poder do do outro agente, pensando agora não só nos três poderes do estado, que tem que colaborar entre si pra pra dar respostas a esse tema, mas também pensando na relação entre o estado, as empresas privadas de tecnologia e as plataformas digitais, e os cidadãos e os movimentos de direitos digitais e a sociedade civil. Então a ideia, uma ideia interessante é a gente pensar em em regular a autorregulação, que seria uma espécie de mezarregulação, como o estado pode ajudar a organizar sistema em que se regula a autorregulação privada, criando piso mínimo de de garantias e de procedimentos que essas empresas privadas, embora sejam transnacionais na maior parte dos casos, vão ter que seguir no no no contexto brasileiro, o que vai dar segurança jurídica pra essas empresas e quais são as suas obrigações, quais são os procedimentos às quais elas estão submetidas, e também dá uma uma satisfação e uma segurança aos cidadãos de quais são os limites, quais são as responsabilidades dos eleitores, dos candidatos, dos partidos. E essa é uma forma de tentar encaminhar então a resposta a como regular o tema da IA no no na seara eleitoral, em que a gente IA no no na seara eleitoral, em que a gente tem que contar com essas três variáveis muito específicas, que são o conhecimento. Quem tem o conhecimento dessas tecnologias e até o domínio, a propriedade intelectual, são os próprios entes a serem regulados, especialmente as as empresas de tecnologia. Elas dispõem do conhecimento e não o estado e as autoridades estatais, não entendem diretamente daquele negócio. Mas ao mesmo tempo quem dispõe do conhecimento é quem tem que ser submetido à regulação. A gente tem a variável do tempo, como criar ambiente regulatório que consiga acompanhar mais ou menos a evolução tecnológica, e a variável do espaço, porque são tecnologias, empresas transnacionais, e a gente está pensando aqui em respostas que o direito brasileiro estatal pode dar com relação a essas tecnologias. Pensando que o direito não é só pra impor obstáculos. O professor Juliano Maranhão falava dessa preocupação em não criar regras sobre proibitivas, criar proibições excessivas que vão obstaculizar o próprio desenvolvimento das tecnologias no que elas têm de bom, exemplo, em baratear, em democratizar as campanhas eleitorais, em facilitar a interação com os eleitores. Mas ao mesmo tempo a gente tem que pensar em como achar essa intersecção entre as vantagens da tecnologia e os nossos interesses, vamos dizer, morais no uso daquela tecnologia. Pra que que a gente quer usar a tecnologia pra expandir a democracia, pra expandir a liberdade de informação e de e de e de participação na política, né? E na falta de uma regulação, na falta de uma coordenação estatal direcionada a esse tema, a gente tem o Judiciário na linha de frente, porque o Judiciário quando ele é provocado a decidir, ele tem obrigação de decidir. E a gente vê isso desde das primeiras ações sobre fake news, a Justiça Eleitoral tem uma dificuldade de consolidar padrões de decisão, porque ela vai decidindo com base no caso a caso e com base na conjuntura política, o que é muito arriscado especialmente no tema eleitoral. Então as decisões nem sempre são previsíveis, nem sempre são isonômicas. E nem sempre são consensuais dentro dum órgão colegiado, às vezes são decisões monocráticas, legislativo precisa contribuir é fazer uma programação prévia dessa decisão judicial do caso a caso, criando uma série de regras, de procedimentos, que têm que ser mais ou menos flexíveis pra acompanhar a evolução da tecnologia, e tem que ser mais ou menos focadas em certos temas, como a gente está discutindo aqui a a importância de ter uma uma regulação da IA no âmbito eleitoral especificamente, que tem os seus riscos, que tem os seus eleitores, que tem o seu tempo específico, a dinâmica eleitoral é diferente de uso da IA pra outras finalidades. A resolução do TSE, que foi bem analisada aqui pela professora Tainá, caminha muito bem nesse sentido, pelo menos é passo inicial, nesse sentido de considerar os usos específicos como alvo da regulação da inteligência artificial? Quer dizer, quais são as consequências que têm que ser mitigadas? Quais são os riscos que têm que ser mitigados na regulação da inteligência artificial, no uso das deepfakes, e assim por diante. Mas o 0 ponto mais importante é, dizer, ter também quer dizer, ter também respostas legislativas que deem anteparo pro judiciário, as plataformas e as empresas digitais, e o povo representado pelas associações de direitos digitais, por esse movimento que a gente tem no Brasil, que é movimento parecido com o movimento ambiental. Como diz o 0 Rafael Zonata, a ideia de direitos difusos que surge pra gente tratar do temas ambientais, que afetam a todo mundo, que afetam todo mundo mas que precisam de representantes que litiguem por esses direitos transindividuais, da mesma forma a gente pode entender os direitos do ambiente digital, e a gente tem associações e uma sociedade civil ativa nesse campo. Então essa última versão do do projeto de lei do Senado tem uma proposta interessante no artigo quarenta, que é esse sistema de governança em que o estado cria uma autoridade, que é uma espécie de articulador de uma rede que envolve agências reguladoras setoriais, agências reguladoras da questão eleitoral, a gente pode pensar se 00A justiça eleitoral é o melhor lugar para ter uma agência reguladora da inteligência artificial na seara eleitoral, ou não, mas o fato é, esses agentes precisam estar coordenados com outras agências reguladoras, com a autorregulação privada das plataformas, com representantes da sociedade civil. E com isso a gente avança num arranjo institucional que dá passo além nessa dinâmica de aprendizagem regulatória que a gente vem tendo no Brasil pelo menos há dez anos desde o marco civil da internet em dois mil e catorze, LGPD em dois mil e dezoito, a proposta de lei das fake news que foi feita em dois mil e dezoito mas ainda tem futuro incerto, e depois a a proposta de de marco regulatório da inteligência artificial. Quer dizer todas todo esse pacote regulatório que o Brasil vem criando ou tentando criar, fala muito de princípios, no caso do PL da inteligência artificial é o princípio da precaução, da prevenção, da mitigação dos riscos, mas se a gente só falar de princípios, a gente está dando discricionariedade à autoridade que vai aplicar esses princípios e vai dar o conteúdo concreto a esses princípios. Então é preciso criar esquema de coordenação entre as autoridades, pra que elas aprendam entre si, qual o conteúdo dá a esses princípios, como criar as regras pro caso concreto, conforme a evolução das tecnologias, e pra que elas também bloqueiam os os abusos de poder, vamos dizer, umas das outras. O PL das fake news falava de autorregulação regulada numa versão anterior, esse esse tema saiu da última versão votada do projeto, o projeto de lei tem tem futuro incerto, mas seria importante que o projeto de lei das da inteligência artificial criasse esse sistema de coordenação entre estado, plataformas EEA sociedade civil. Isso seria passo além, e se a gente pensar na contribuição específica pro campo eleitoral, de ter regras que vão endereçar os problemas dos atores que estão envolvidos nesse campo, os partidos, os eleitores, os candidatos, e a dinâmica específica do processo eleitoral e os usos que a inteligência artificial tem no processo eleitoral. Então a gente está pensando aqui não em criar uma código, como se como se pensava no século dezenove, código civil pra durar duzentos, trezentos anos, com milhares de artigos, mas o mais importante seria organizar como vai ser a interação entre as autoridades que vão tomar a decisão sobre esses temas, uma forma de coordenação procedimental experimental entre essas autoridades, pra que elas vão, pra que elas consigam desenvolver em conjunto as regras acompanhando a evolução tecnológica. De modo que a gente está muito acostumado a pensar na evolução, na inovação em termos econômicos, tecnológicos, a criação de novos produtos, de novas novos métodos de produção, mas a gente costuma ver o direito só como uma imposição de obstáculos. E na verdade a gente também deveria ver o direito não só como a criação de regras, procedimentos, mas também como a criação de novos regimes jurídicos. E pro ambiente digital a gente tem que pensar num tipo de regime jurídico que catalise, que facilite a coordenação entre executivo, legislativo, justiça eleitoral, plataformas digitais transnacionais, atores locais, já que a gente tem a justiça eleitoral nesse papel de organizar as eleições e também de ser órgão jurisdicional, e também a sociedade civil, a academia, enfim, acho que a gente tem representantes aqui hoje de vários dessas, vários desses polos que estão interessados e cada tem o seu conhecimento, a sua legitimidade E0EE uma parte de interesse a ser defendido e que tem que ser coordenado no desenho dessa legislação. Então o que eu queria, enfim, fechar minha fala dizendo que ponto importante além dessas questões de analisar 000 risco, o conteúdo, as consequências, as aplicações específicas da inteligência artificial em campo ou em outro, daí a importância da discussão ser focada no campo eleitoral, a gente tem que pensar o direito como desenho de esquema de interação que vai se perpetuar entre diversos agentes, pra que eles consigam aprender ao longo do tempo como ir desenvolvendo regras mais ou menos flexíveis pra acompanhar essa evolução tecnológica. É isso, queria deixar tempo aí pro debate e pras outras intervenções. Muito obrigado. Obrigado, professor Lucas",
      "speaker": {
        "name": "Lucas Amato",
        "position": "Prof. Dr. USP"
      }
    },
    {
      "id": 4104309,
      "start_time": 1715254552,
      "duration": 26,
      "transcription": "",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104343,
      "start_time": 1715254578,
      "duration": 890,
      "transcription": "E a todos. Começo com a saudação ao Krenak, que foi constituinte de oitenta e oito hoje na Academia Brasileira de Letras e também a Gilberto Gil. Hoje nós vamos falar de tema que envolve a eleições, mas que envolve sobretudo a nossa cultura constitucional. Então é fundamental começar por aí. As discussões aqui hoje nos painéis foram muito ricas, né? A gente tem aqui uma discussão bem focada sobre o tema da regulação da inteligência artificial, temos PL que está em discussão, está na ordem do dia, mas eu queria se possível, na linha até das considerações do professor Lucas Amato, apresentar uma perspectiva da qual a gente compartilha teoricamente, a obra do professor Roberto Mangabeira Húnger, que é de pensar o direito e as instituições como mecanismos de transformação do estado brasileiro. Então especificamente no tema da regulação da inteligência artificial e a Justiça Eleitoral e as eleições, a gente tem elefante no meio da sala. E esse elefante é o desenho constitucional e institucional do Tribunal Superior Eleitoral. O Tribunal Superior Eleitoral, nos termos da constituição e do código eleitoral, e a gente precisa frisar isso, que é uma legislação que foi aprovada né, quatro sete três sete de sessenta e cinco, em plena ditadura militar, trouxe uma configuração bastante autoritária pro Tribunal Superior Eleitoral, a ponto dele concentrar em si poderes de caráter jurisdicional, e com esses todo mundo numa democracia está bem confortável, mas também de concentrar outros poderes, poderes que são quase normativos, quase legislativos. Então a gente passou a discutir a regulação das eleições no Brasil como se resoluções do TSE fossem naturais. E eu acho que a gente tem uma belíssima oportunidade pra pensar essa modelagem. Porque afinal de contas, passados todos esses anos, será que essa arquitetura constitucional, que concentra os poderes de regulação das eleições exclusivamente no TSE, ainda funciona? Faz sentido numa sociedade em que há Big Techs? Em que há vários usos dessas tecnologias? Em que o Brasil configura em termos de usuários como dos quatro maiores mercados, e que tem uma das sociedades civis mais ativas no assunto, e eu saúdo aqui, foi até a menção do professor Lucas Zamato, o professor Zanata, Rafael Zanata, que juntamente com essa dimensão dos direitos difusos, traz também uma reflexão sobre o chamado tecnoautoritarismo. E é sobre isso que eu queria pontuar a minha fala, trazendo aqui algumas obras de referência, mil novecentos e oitenta e quatro, isso não começou agora, isso já é antigo, em mil novecentos e quarenta e nove, George Walwell trouxe uma reflexão de qual que é o risco da gente falar de ministério da verdade, minivero. Será que o TSE é esse ministério da verdade? Eu tenho dúvidas, não como oposição ao TSE, mas pra dizer que o modelo de governança no Brasil pode ser melhor. E pode ser melhor de que maneira? Fazendo coro aqui com a fala do professor Lucas, e da professora Tainá, trazendo governança, trazendo uma visão multissetorial, trazendo uma perspectiva que integre modelo de governança em que esse sistema nacional que o antiprojeto hoje o projeto né, perdão, o PL mesmo no seu substitutivos consagra, que ele possa interagir com o sistema eleitoral. E quando a gente fala do sistema eleitoral no Brasil, e aí eu gostaria de mencionar que consta está aqui no nosso auditório, professor Henrique Smith Simon, nós temos publicado nesse campo, há algum tempo já, levantando a maneira pela qual o Tribunal Superior Eleitoral tem tratado da das resoluções nesses temas. E o que a gente percebe é que desde que o assunto da inteligência artificial e da regulamentação das eleições no Brasil passou a figurar especificamente nas resoluções do TSE, o que nós temos é muito mais elemento simbólico do que propriamente uma atuação efetiva do Tribunal Superior Eleitoral. Nós fizemos levantamento, é paper que apresentamos ano passado em junho do ano passado, lá em Lisboa, está no Prello pra publicação, em que a gente levanta desde a gestão da ministra Rosa, ministro Barroso, ministro próprio Alexandre de Moraes, situações nas quais o que é declarado simbolicamente não corresponde Então o que a gente precisa saber é será que essa modelagem é atual? E aí eu vou trazer o exemplo pelo qual passamos nas últimas eleições, e acho que isso é muito importante destacar, porque o quadro eleitoral de dois mil e vinte e dois, foi muito problemático. Nós tivemos uma polarização muito grave, nós tivemos uma situação em que resolução do TSE foi editada entre o primeiro e segundo turno das eleições. E neste país, ao que consta ainda, ainda há o texto do artigo dezesseis do texto constitucional que estabelece o princípio da anualidade eleitoral. Então independente do que que esta casa né o Congresso vai determinar a título do PL, nós vemos com muita preocupação o fato de que estamos há menos de seis meses das eleições municipais, e pro horizonte próximo, são as eleições gerais de dois mil e vinte e seis, a gente ainda não tem uma regulamentação que modifique essa estrutura que nos parece ainda muito muito autoritária, ela precisa ser atualizada, ela está caduca, e seria muito bom que o Tribunal Superior Eleitoral pudesse contar e aí as próprias dúvidas que o professor Lucas Amato acabou de apontar né, quer dizer, será que será que vai ser uma agência né? Como é que a gente vai modelar isso? O fato é que o TSE sozinho, e muito menos quem quer que esteja na presidência, não tem condições de infalibilidade num sistema e num mundo que está cada vez mais complexo. A gente precisa ter uma estruturação em que haja uma governança em que o mercado tenha a possibilidade de apresentar a sua visão com as tecnologias emergentes, a sociedade civil com a proteção desses direitos difusos, os usuários e as entidades do estado brasileiro. Só que se a última canetada for uma canetada dada aos quarenta e cinco minutos por quem estiver na cadeira da presidência do TSE, e é assim uma regulamentação, na e que é uma regulamentação na minha percepção autoritária, porque ela se defasou com o tempo, ela não está compatível com o modelo inclusive pluripartidário que o Brasil ostenta, então é exatamente nessa linha, eu queria destacar aqui que além de mil novecentos e oitenta e quatro a gente precisa resgatar as origens de uma outra obra clássica, foi publicada ano antes que em mil novecentos e oitenta e quatro, que é o nosso querido Vitor Nunes Leal, coronelismo inchado e Voto. Nós temos diante de nós uma oportunidade de renovar o sistema eleitoral no Brasil, transformálo, para que a gente tenha condições de fortalecimento da cidadania. Me recordo aqui inclusive que esse foi dispositivo que a professora Tainá destacou na apresentação dela o artigo segundo, é dizer pra além da gente enunciar né a importância desse princípio, nós pensarmos essa transformação como mecanismo de fortalecimento da cidadania, e não dos novos coronéis, porque o que a gente está vendo aí, inclusive no impasse que se deu né, entre o atual CEO do Schuitter né do X, com o então presidente do Tribunal Superior Eleitoral, é que nosso novo coroelato agora é transnacional. Então a gente precisa entender que são novos desafios, e se nós não nos prepararmos porque essa é uma questão de estratégia e de desenvolvimento nacional, essa é uma questão de estratégia e de desenvolvimento nacional, e aí chamo novamente à mesa, professor Roberto Mangabeira Húnge, com a percepção da economia do conhecimento, a gente vai ficar a gente perde uma oportunidade de sair à frente. E acho que o Brasil tem sim todas as condições pra apresentar uma nova versão a título de dessa nova mudança né, da estrutural da esfera pública, e uma boa forma de fazer isso seria modificando os poderes do Tribunal Superior Eleitoral e também a maneira pela qual a regulamentação das eleições acontece no Brasil. Hoje o que nós temos no Brasil, são as chamadas minireformas eleitorais. Então pra cada eleição eu chamo isso, chamamos isso, professor Henrique e eu chamamos isso de puxadinhos eleitorais. A gente não pensa estruturalmente o processo eleitoral no Brasil, desde noventa e sete, acho que chegou o momento da gente parar pra pensar pouquinho e aqui é sem a pretensão que muito bem o professor Lucas Zamatto aqui sinalizou, não estamos aqui com a ambição, com a ilusão de que uma legislação vai perdurar por muitos anos, mas a gente precisa que pelo menos ano, que é o que a constituição pede, que a gente tenha clareza das regras. E a gente não está tendo clareza dessas regras. A título de sugestão, né, uma vez que preciso encerrar a minha fala, eu diria que, não adianta uma fala que seja crítica sem que ela proponha nada no lugar, né. Então essa é bem na linha do nosso professor Roberto Mangabeira Húngaro, que pudemos servir por duas oportunidades tanto no governo Lula dois quanto no dia a dois na na na Secretaria de Assuntos Estratégicos. Então o que que me parece interessante? A primeira coisa é a gente modelar alguns engenhos, alguns mecanismos de engenharia institucional. O primeiro deles é modificar essa competência do TSE. Do jeito que está, a gente vai continuar a assumir que a Então enquanto Enquanto não uniformizarmos, a gente tem problema de diálogo de fontes inclusive, e o problema de uma legislação voltada especificamente pra IA, é que na hora que ela for interpretada pelo TSE, o TSE vai dizer que ela não incide lá, porque lá vale o contencioso eleitoral e a gente conversou com a fala do Tainá, a fala do Lucas, a gente tem esse casuísmo essa judicialização que tem sido muito perniciosa no Brasil. O segundo elemento é que me parece que a lei das eleições no Brasil, ela está modelada pra abusos né, abuso de poder econômico, abuso de poder político, e a gente precisa de uma nova categoria de abuso. E eu chamaria, inclusive na linha dos estudos de comunicação, de abuso de poder comunicativo. Porque a gente passa a ter a partir de agora, o uso de inteligência artificial generativa de maneira abusiva, de maneira a interferir na própria formação da opinião e da vontade das pessoas. E essas mudanças, elas não são definidas só de imediato, não é só uma coisa de checagem de fatos. Ah dead é fake ou é verdade? Não é só isso gente. Quando nós observamos o que aconteceu aí nos incidentes da Cambridge Analítica, do Brexit, né, as próprias questões relacionadas aos lamentáveis atos de oito de janeiro, que a própria arquitetura aqui dessa casa ainda não está recuperada do que fizeram aqui em oito de janeiro, os danos ainda são perceptíveis. A gente precisa de mecanismos de médio longo prazo pra observar a construção da verdade, e o controle dessa verdade. Na verdade eu não acho que nem seja uma questão de buscar a verdade a gente precisa lidar com a chamada não é nem a pósverdade é a pósmentira, quer dizer a partir do momento que houver uma campanha que tiver sido impulsionada ou por robôs ou por meios econômicos, que nós tenhamos mecanismo, uma câmara de observação técnica sobre se a formação daquele consenso foi adequado ou não. Então nós teríamos com essa sugestão, uma espécie de espaço de observação de abusos, não apenas durante o período eleitoral, e essa é a terceira contribuição que eu gostaria de trazer, porque hoje a regulamentação das eleições fica apenas pautada em abusos durante as eleições. E a gente tem que entender que se o modelo é democrático, e se a gente está falando de circulação de opinião e vontade política durante todo o período, porque afinal de contas a gente usa durante todo o período, a gente precisa ter uma câmara de ressonância pra observar a saúde e os excessos relacionados ao sistema eleitoral. Então para essas essas situações de abuso comunicativo algoritmo, nós teríamos aí uma ferramenta pouco mais ampliada, e pra deliberar tecnicamente sobre esse assunto me parece que o assunto não deveria ser definido pelos sete ministros do TSE não, o ideal seria ter uma câmara técnica, trans indisciplinada quer dizer com pessoas de vários segmentos da área do conhecimento e de diversos setores, pra qualificar se aquele incidente de comunicação que se desdobrou por alguns anos, se ele foi viciado ou não. Eu agradeço encerrando a minha fala, agradecendo ao professor Ricardo, que nos fez o convite, ao deputado Áureo, e também ao ao Caio que nos deu as boasvindas em as boasvindas em especial gostaria de parabenizar e em nome da casa aqui o amigo querido que é o Márcio Rabat, que é aqui dessa casa, servidor da casa com muito orgulho, ele serve muito bem essa casa. Muito obrigado.",
      "summary": " Prof. IDP e UNB propõe revisão constitucional em regulação IA e Justiça Eleitoral. Ele sugere um modelo de governança multipartidário, com atores como mercado, sociedade civil, usuários e estado. Ele alerta por regulação autoritária do TSE e enfatiza clareza nas regras, modificações de competência do TSE, nova categoria de abuso e mecanismos de observação médio-longo para construção e controle da verdade.",
      "speaker": {
        "name": "Daniel Augusto Vila-Nova",
        "position": "Prof. IDP e UNB"
      }
    },
    {
      "id": 4104312,
      "start_time": 1715255468,
      "duration": 18,
      "transcription": "Obrigado, Professor Daniel. Eu queria passar então a palavra ao Kabisaja pra poder fazer a interlocução com os com os panelistas, por favor Caio. Dado que a gente tem só nove minutos pro próximo painel",
      "summary": " Mestre de Cerimônias pediu a palavra para Kabisaja, para introduzir os panelistas nos próximos nove minutos.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104318,
      "start_time": 1715255486,
      "duration": 87,
      "transcription": "Fazer uma pergunta mais objetiva e também, se puderem responder de forma excincisa, porque muito se fala na necessidade da gente pensar em uma lei viva pra lidar não só com a inteligência artificial, mas com esses fenômenos das novas tecnologias digitais que são muito dinâmicos, de forma que a gente não poderia tentar regular essas tecnologias como o professor Lucas Zamatto falou, pensando em código ali pretensamente perene. A gente tem que pensar em uma forma de regulação dinâmica, que possa acompanhar as as mudanças da tecnologia. Então eu queria comentário de cada se vocês pensam que o atual texto apresentado pela Comissão de IA do Senado, se ele tem essa visão, se as, se esse desenho regulatório que ele propõe é adequado a essa abordagem verticalizada e dinâmica, ou se precisaria avançar em algum algum aspecto e, enfim, como isso se relaciona com a regulação da IA em eleições, como a regulação em âmbito eleitoral se conectaria a esse sistema regulatório aí mais mais dinâmico mais, mais aberto. Bom vou tentar serrar.",
      "summary": " USP questioning the adequacy of the current senate committee's regulatory proposal for AI, highlighting the need for dynamic regulation that keeps pace with technological changes and its relevance to election regulation.",
      "speaker": {
        "name": "Caio Missagia",
        "position": "USP"
      }
    },
    {
      "id": 4104317,
      "start_time": 1715255573,
      "duration": 80,
      "transcription": "",
      "speaker": {
        "name": "Tainá Junquilho",
        "position": "Profa. UNB e IDP"
      }
    },
    {
      "id": 4104340,
      "start_time": 1715255653,
      "duration": 208,
      "transcription": "Bom, acho que a a gente tem a professora Tainá muito mais qualificada pra fazer uma apreciação geral assim do do do projeto de lei do Senado. Mas eu acho que, por mais defeitos que tenha projeto de lei, a gente está numa situação pior do que ter uma lei ruim que é não ter nenhuma lei. É a mesma frustração que a gente tem desde a da discussão sobre a lei de fake news. Quando a gente fez uma pesquisa sobre a lei de fake news, a nossa esperança era que essa lei tivesse sido aprovada e fosse aplicada pra gente ver os efeitos dessa lei e os defeitos dessa lei dentro de prazo do projeto de pesquisa. E o fato é até hoje em dia a gente não tem essa regulação. Espero que não se repita o mesmo destino com esse projeto de lei do inteligência artificial. Como eu disse, ele ele traz uma ideia que já era interessante, a ideia da da autorregulação regulada, que agora é chamada de governança policêntrica, enfim, com outros termos no no projeto da inteligência artificial, sistema nacional de coordenação de governança da inteligência artificial, seria importante colocar em teste prático esse sistema porque na falta de sistema como esse, a gente tem os atores atuando isoladamente em uma dessas duas posições, ou uma posição simbólica, ineficaz, a plataforma dizer que está autorregulando, o legislativo ou o judiciário declara uma série de princípios e tudo o mais, e isso fica entre o simbolismo e o autoritarismo, porque aí o tribunal, em nome de assumir a sua competência para julgar esses problemas, ou o Legislativo, ou as plataformas digitais, eles acabam tomando pra si decisões meio opacas, discricionárias ou até arbitrárias. Então a gente fica entre a inefetividade e o autoritarismo. E a saída disso seria ter sistema de coordenação em que a gente supõe que todo mundo vai errar, como dizia o professor Daniel, a falibilidade de todos os agentes, mas que agente pode ajudar a consertar, impor freios sobre o outro e ajudar com que o outro a gente aprenda, entenda melhor a tecnologia, ou entenda melhor quais são as demandas da democracia que não são compatíveis com as demandas de lucro da empresa de tecnologia, enfim, porque na falta disso a gente fica com essas figuras, com esses conflitos personalizados entre o dono da plataforma, o presidente do tribunal, que muda amanhã, e amanhã vai ser outro conflito encenado, entre posições autoritárias ou simbólicas, mas nada disso cria esquema perene para a gente continuar aprendendo a regular essas tecnologias, que, embora todos sejam especialistas aqui, para todos é uma novidade. Então a gente precisa ter esquema em que cada consiga trazer pouco do seu conhecimento, pra ir desenvolvendo essa regulação ao longo do tempo, né? Então acho que pior do que ter, por pior que seja projeto, por mais defeitos que tenha o projeto das fake news, ou que tenha a versão atual do projeto da inteligência artificial, o pior é não ter nenhum aparato legislativo e a gente ficar nesse embate direto entre a plataforma transnacional e o presidente da época do da Justiça Eleitoral, do Tribunal Superior Eleitoral. Bom",
      "summary": " Prof. Dr. USP considera projeto lei inteligência artificial com defeitos preferível à falta de regulamentação. Autorregulação regulada proposta é interessante, um sistema de coordenação necessário para desenvolver regulamentação efetiva ao longo do tempo. Melhor ter projeto com defeitos do que nenhum aparelho legislativo, evitando conflitos entre plataformas transnacionais e autoridades locais.",
      "speaker": {
        "name": "Lucas Amato",
        "position": "Prof. Dr. USP"
      }
    },
    {
      "id": 4104345,
      "start_time": 1715255861,
      "duration": 296,
      "transcription": "Bem bem objetivo Caio, de fato essa é uma demanda a demanda de regulação ela existe há algum tempo, junto com o professor Paulo Renato da Silva Santarém, que coordena o a qual TuneLab e que tivemos a oportunidade de ombrear o IBIDEM, é o Instituto Brasileiro de Internet e para a Democracia, nós publicamos há quatro anos em dois mil e vinte artigo que saiu no portal do J, justamente pontuando essa necessidade da regulação, de ter uma legislação. À época, nós começamos esse artigo buscando, parece até parece até brincadeira, mas buscando uma fala do então CEO ele ele não era ainda ele não era ainda o CEO da X ainda eu acho que ele ainda ia comprar ele estava como dono da Tesla. E foi uma conferência uma né lá em na Califórnia em que ele disse o seguinte o Elon Musk falou que a inteligência artificial estaria para o século vinte e assim como energia nuclear esteve para o século vinte. E foi nessa mesma semana que ele fala e fala isso há quatro anos gente era alta pandemia. Isso é março abril de dois mil e vinte está registrado isso nesse artigo no portal no J. Foi a mesma semana em que aqui em Brasília, no Supremo Tribunal Federal, o então presidente do Supremo, ministro Dias Toffoli, determinou nos termos do regimento do Supremo, indicou a relatoria do ministro Alexandre de Moraes para o inquérito, chamado inquérito do fim do mundo né? E a as discussões seguem conectadas né porque, se a gente não tiver a definição de regras mínimas né, o professor Lucas aqui pontuou né essa questão da a divisão dos poderes por meio do do projeto, nós não vamos avançar. De outro lado, todas essas esses elementos dinâmicos que a professora Tainá suscitou me parece eu vejo com muito bons olhos, né eu acho que mais importante do que não haver nada a respeito, é a gente ter marco a partir do qual a gente começa a discutir esse assunto de maneira mais ampliada, de maneira mais intersetorial, com participação da sociedade civil, com participação do mercado e com participação dos agentes do estado, passando a discutir esse assunto como com uma agência, né? Porque há uma questão de gerenciamento normativo da da realidade, como diz o professor Carlos Arissuiffeld. Agora, os desafios do ponto de vista para as eleições eu eu mantenho assim, eu acho que a gente não vai conseguir mexer nisso porque sem modificar as competências do TSE E0A modelagem das eleições a gente vai entender é aquele bordão né latino lexis especialis né de rogatti regenerais né, então o TSE vai entender que a lei eleitoral ela é espaço próprio de aplicação da IA pra fins eleitorais e poder consagrar esse passo até porque poder consagrar esse passo, até porque, professor Lucas falou isso, eu encerro aqui a minha resposta sim. A experiência do marco civil da internet né que completa onze anos, ela fez uma adoção que é uma uma adoção de gestão desses assuntos de arbitra se houve excesso ou se não houve excesso. E eu acho que a caminhada na linha inclusive do que foi a exposição da professora Tainá, é da gente desjudicializar, trazer pra uma dimensão mais administrativa esse assunto. Me parece que é caminho mais adequado porque o judiciário tem outro tempo, o judiciário não tem a visão técnica ele não tem capacidade institucional e aqui não é nenhuma crítica pessoal a quem quer que seja, o Judiciário está preparado pra outro tipo de modelagem de conflito, isso é o clássico da separação de poderes, então quer dizer pra lidar com o assunto que é hightech em alta velocidade, quer dizer, o 0 Poder Judiciário no Brasil até hoje discute de terras indígenas, que é uma coisa ancestral. Vem me dizer que qual que vai resolver o problema da comunicação da rede numa alta velocidade? Gente olha, dizem que jabuti às vezes para em cima de projeto de lei, mas esse jabuti aí tem que ser muito veloz, muito mágico. É isso. Obrigado professor.",
      "summary": " Prof. IDP e UNB enfatizam necessidade de regular IA há quatro anos, a equivalendo à energia nuclear do século XX. Cita artigo do J, opiniões de Musk, e inquérito no STF. Menciona participação de sociedade civil, mercado, e agentes do Estado. Discussão sobre desafios para eleições com IA e sugestão de desjudicializar processo, propondo abordagem administrativa com consideração ao tempo e preparo limitados do Judiciário em face de conflitos de alta tecnologia em alta velocidade.",
      "speaker": {
        "name": "Daniel Augusto Vila-Nova",
        "position": "Prof. IDP e UNB"
      }
    },
    {
      "id": 4104321,
      "start_time": 1715256157,
      "duration": 136,
      "transcription": "Daniel, obrigado aos membros do Painel. Obrigado professora Tainá, Caio, obrigado professor Lucas E com isso a gente desfaz o esse nosso esse nosso segundo painel. E eu gostaria de chamar então o terceiro painel sobre as redes, os representantes de cada uma das redes, então eu gostaria de chamar o Marcelo Lacerda, diretor de Relações Governamentais do Google, o Fernando Gallo, diretor de políticas públicas do TikTok, e a Margarete Kang, que é gerente de políticas públicas e estratégias de engajamento da Meta, por favor. Tudo bom? Prazer. Eu peço então pra gente iniciar esse nosso terceiro e último painel, assim que os convidados estiverem prontos, que a gente vai começar pela pela MegKang da da Meta pra fazer suas considerações. A apresentação dela por gentileza, e eu vou pedir aqui aos convidados, por gentileza, que quando a gente está com uma técnica, quando for mover o slide pedir oralmente durante a apresentação pra mover, de slide pra outro, obrigado.",
      "summary": " Mestre de Cerimônias anunciou o terceiro painel sobre redes, apresentou Marcelo Lacerda, Fernando Gallo e Margarete Kang, da Meta, e solicitou que os convidados estejam atentos às instruções durante as apresentações.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104331,
      "start_time": 1715256293,
      "duration": 1191,
      "transcription": "Quase a hora do almoço, espero que todos estejam aí firmes e fortes, eu sou a Meg, gerente de políticas públicas da Meta, agradeço primeiramente a oportunidade da gente estar aqui conversando e dialogando sobre esse assunto que é tão caro e importante pra todos nós. E eu acho que é uma boa oportunidade da gente dar pouco mais de visibilidade do trabalho que a Meta faz em termos de desinformação. Foi colocado aqui anteriormente a importância da de nós pensarmos a desinformação não só no contexto eleitoral, mas como de uma forma mais holística né, porque a desinformação ela está não só em períodos eleitorais, mas em todos os momentos. E nesse sentido, o próximo slide por favor. Queria destacar a nossa missão na meta que é de fato dar às pessoas o poder de criar comunidades e aproximar o mundo. E aí eu vou trazer número pra vocês que é superinteressante. Próximo slide? Esse. Nós temos hoje três bilhões de usuários conectados na Meta, no mundo inteiro, e cerca de cem milhões de conteúdos que, e de peças de conteúdos que passam diariamente, sendo uma média de milhão vírgula cento e cinquenta milhões de peças por segundo. Vejam a quantidade, né, e o tamanho de informações que circulam em nossas redes todos os dias. E aí focando pouco em como nós trabalhamos pra modelar esse conteúdo, para pra moderar esses conteúdos, para entender se esse conteúdo pode ser desinformativo ou não, além de outros critérios, próximo slide. Nós temos aqui a construção de regras. As nossas regras, que são as nossas políticas, determinam aquilo que pode ou que não pode ser compartilhado dentro das plataformas. Essas regras estão estabelecidas dentre os nossos padrões da comunidade, que está presente na nossa central de transparência, então, pra aqueles que ainda não conhecem, nós temos uma central, nessa central nós temos os padrões da comunidade, que são as políticas, que são as regras da Meta, pra aplicativos específicos como o Instagram por exemplo, além dos padrões da comunidade é importante entender regras específicas adicionais que estão disponíveis nas diretrizes de comunidade da do Instagram. Então nós trabalhamos com esse conjunto de regras diariamente. E aí me perguntam, como que vocês fazem então pra gerir tamanha quantidade de conteúdos? Próximo slide. Nós trabalhamos de uma forma muito holística pensando não só naquilo que a tecnologia pode fazer, mas entendendo que por vezes nós precisamos de equipes treinadas, de pessoas, de seres humanos, e contamos ainda com a denúncia dos usuários. De novo com números porque números não mentem. Hoje, cerca de noventa e cinco por cento dos conteúdos que têm alguma violação das nossas políticas, esses conteúdos são pegos, eles são retirados, não são possíveis de ir ao ar em razão da nossa inteligência Nesse Nesse sentido, aquele remanescente que acaba subindo, ele vem e vai ser analisado por nossos indicadores de fatos, por por denúncias dos usuários, e assim por diante. A nossas equipes, inclusive as nossas equipes humanas, elas estão disponíveis vinte e quatro horas por dia, sete dias por semana em mais de sessenta idiomas. Próximo slide? Quando nós fazemos então, pensamos de uma forma pouco mais recortada na desinformação, e e aí antes de fazer isso eu destaco que a nossa estratégia em termos de violação das políticas é remover, reduzir e informar, nós também aplicamos essa estratégia para a desinformação, eu vou explicar pra vocês pouquinho mais adiante. Nós temos uma política específica pra desinformação no próximo slide, e ela existe há muito tempo, e ela vem sendo atualizada com constância. Se aplica não só pra períodos eleitorais e pra contextos eleitorais, mas pra qualquer conteúdo desinformativo. Só que a desinformação ela é pouco diferente dos outros critérios analisados, porque é impossível a gente ter uma lista abrangente de todas as proibições. A desinformação ela tem diversas nuances. Então o professor Juliana trouxe aqui o exemplo da Tábata Amaral. Então pode parecer que aquilo é uma desinformação, mas é uma sátira. Então ela pode ter contextos de humor, contextos de sátira, contextos informativos, pode ser simplesmente boato, então é muito interessante entender que a desinformação ela não é tão simples assim ser analisada. De qualquer forma, a Meta entende que nós não somos os donos da verdade. E para que o conteúdo seja, de fato, bem analisado, nós fazemos parcerias com checadores de fato. Hoje no mundo, nós temos mais de oitenta empresas checadoras de fato, que são parceiras da Meta, e elas trabalham em mais de sessenta idiomas. No Brasil, nós temos seis empresas parceiras que fazem a checagem de fatos então, dentro dos aplicativos da Meta. Além do programa de indicadores de fato, que é aí uma parceria com as agências que têm a certificação internacional dos indicadores de fato, nós temos categorias pra pra pra identificar as informações quanto a a sua a sua gravidade em termos de desinformação próximo, e essa gravidade ela vai determinar aquela desinformação ela vai ser retirada, se ela vai ser simplesmente informada, ou se o seu alcance vai ser limitado. Dentro da nossa política de desinformação nós temos uma política específica da mídia manipulada, que é assunto que está super quente hoje, mas eu destaco que essa política de mídia manipulada existe desde dois mil e vinte. Ela vem sofrendo atualizações constantes, e hoje, quanto à mídia manipulada, nós removemos conteúdos que podem que são usados, que são fabricados ou que são editados por mídias sintéticas, por inteligência artificial, e que buscam desenformar, que de alguma forma, os usuários. Não é simplesmente conteúdo como aquela foto que nós vimos na onde ela colocou né o prefeito Ricardo dentro da imagem do Ken, mas são imagens, são vídeos que podem de alguma forma levar uma pessoa a entender que aquela pessoa disse uma coisa que ela não disse, que ela fez uma coisa que ela não fez. Então existe todo contexto específico. E outro critério adicional, é que essa mídia tenha sido aí alterada ou formulada através da inteligência artificial ou do aprendizado de máquina por exemplo, que são os casos das deepfakes. Então, uma mídia manipulada dentro das plataformas. Pensando então no próximo slide, em quais, em quais tipos de informação nós removemos as plataformas, que são as mais graves? São então os conteúdos que podem trazer alguma agressão física ou alguma violência no mundo real, desinformação prejudicial sobre saúde, interferência eleitoral ou censitária, e mídia manipulada. A mídia eu acabei de explicar pra vocês, e eu acho que pro nosso contexto aqui vale entender pouquinho sobre a interferência eleitoral ou censitária. Nesse caso, nós removemos os conteúdos que, de alguma forma, limitam a capacidade das pessoas de de participarem do processo democrático. Por exemplo, desinformação sobre a data da votação, sobre o local, sobre a capacidade, sobre quem pode votar e quem não pode, sobre os números dos candidatos. Essas são informações que limitam a capacidade do de nós cidadãos, de participar do processo democrático, e nesse caso, é gravíssimo e nós tiramos das plataformas. Só que próximo slide por favor, para outros tipos de desinformação, nós entendemos que as pessoas merecem saber por que que aquilo é desinformação. Elas merecem entender como que a agência secadora checadora de fato, catalogou aquilo daquela maneira. Elas as pessoas merecem ter oportunidade de conversar sobre esse assunto. Então, nós entendemos que diminuir a prevalência, colocar avisos, colocar cortinas de fumaça, são formas também de promover o debate público e de informar acima de tudo os usuários. Próximo. Como nós, como como eu já introduzi, a gente tem muitas formas de entender conteúdo quando ele aquele conteúdo é alterado, e para alguns pode ser de desinformativo, mas pra pode ser apenas uma sátira, uma paródia, ou conteúdo fabricado, né, e aí existem várias formas de você catalogar isso. Quem faz essa catalogação, eu repito, são as agências secadoras, existe toda a metodologia, mas quem faz essa catalogação são as agências. Quanto nós próximo, resolvemos reduzir então, então nós temos aquelas categorias mais graves de emoção, mas quando nós entendemos que reduzir é melhor, é porque esse conteúdo de alguma forma, ele precisa ser orientado. É é muito engraçado que às vezes a gente tem conteúdo muito parecido com o outro, mas em razão de uma nuance muito específica, ela pode ter o outro tipo de contexto. E pra que isso possa ser melhor observado pelos usuários, nós preferimos manter, reduzindo o alcance e colocando, não sei se vocês já viram, etiquetas ou aquelas cortinas. E de acordo com os nossos, nossa aplicação da inteligência artificial, e da nossa a nossa aplicação da estratégia sobre esse ponto, a nossa experiência é muito boa. Quando nós colocamos por exemplo, ou rótulo ou aquela cortina, cerca de noventa e cinco por cento das pessoas, não clicam, não chegam a ver aquele conteúdo, não querem abrir aquela cortina, não querem, não estão mais interessadas naquele conteúdo. Próximo. Nós utilizamos como eu falei pra vocês, adicionalmente, a questão do informar. E esse informar, ele é muito importante porque quando as agências fazem a análise daquele conteúdo, elas fazem todo estudo. Elas buscam em fontes e informam, dentro desses dentro dessa análise que elas fizeram, onde elas encontraram as fontes fidedignas. E isso é importantíssimo para nós usuários, para que nós possamos escolher onde nós queremos buscar mais informação, por que aquele conteúdo foi refutado, e assim por diante. Próximo. E, além disso, além de informar, além de sinalizar, além de remover, além de colocar né todas essas dificuldades para que as pessoas possam ter acesso a essa informação, nós nós trabalhamos com outros tipos de estratégias que aumentam aí a efetividade da no do combate à desinformação. Primeiro deles, quando nós falamos em encorajar as pessoas a decidir o que ler e e como fazer, a as etiquetas são super importantes próximo por favor, e e dessa forma quando nós informamos melhor e informamos de forma muito clara, nós entendemos que de alguma forma, essa estratégia não só do combate, mas de educação, que hoje foi pouco falado, é super importante. Próximo. Ao trabalharmos com as agências secadoras de fatos, as agências não trabalham de forma elas são independentes, mas nós utilizamos todo aquele conteúdo analisado pelas agências pra alimentar a inteligência artificial. Então vamos supor que conteúdo foi classificado como conteúdo falso pelas agências, a nossa IA vai reconhecer aquele conteúdo e vai impedir que conteúdos duplicados que já foram checados subam na plataforma novamente. Se a agência classificou aquele conteúdo como boato, quando conteúdos iguais forem subirem através de outros usuários, a inteligência artificial vai aproveitar o conhecimento já produzido pela pelas agências, para que esse conteúdo possa então ser informado para os usuários. Para além disso próximo, por favor, nós bloqueamos milhões de contas falsas todos os dias. E por que conta falsa? Por que as pessoas criam contas falsas? Porque contas falsas têm aí a possibilidade de trazer muitos conteúdos enganosos. E nós entendemos que as contas falsas podem ser grande uma grande porta para esses conteúdos desinformativos. Então esse essa é uma outra estratégia conjunta pra evitar os conteúdos que têm desinformação. Agora eu vou entrar numa parte que interessa a todos, que é pouco mais dentro do assunto da inteligência artificial propriamente dita, e das novidades que nós trazemos quando nós pensamos na IA generativa, na IA de propósito geral, que muito foi falado hoje pelos painelistas. Próximo por favor? Dentro da Meta, a IA não é uma tecnologia recente. Como vocês mesmo podem ver, nós usamos a inteligência artificial pra moderar conteúdos. Dos exemplos que eu trago pra vocês, são as linguagens são os né, as as grandes os grandes modelos de linguagem. Não sei quantos aqui conhecem os grandes modelos de linguagem, mas nós já estamos aplicando esses modelos dentro dos nossos padrões de de moderação de conteúdo, pra que eles possam por exemplo, tirar as informações que não têm nenhum potencial de ser falso, da fila da checagem de fato dos nossos checadores. Isso diminui muito a quantidade de informações que eles têm para serem checados por exemplo. A nossa as nossas linguagens elas estão sendo utilizadas para que a gente possa detectar padrões, e assim por diante. Essa é uma aplicação que vem sendo utilizada desde muito tempo atrás, mas que vem sendo melhorada e e ganha uma evolução com o tempo. Uma atualização recente que nós fizemos, próximo por favor, é no da questão da rotulagem de imagens de inteligência artificial. Nós temos uma estratégia focada em conteúdos orgânicos, e e não sei se vocês conhecem essa essa terminologia, que são os conteúdos nós vamos produzindo diariamente, e conteúdos que são os anúncios, que são os impulsionados né, que são pagos pelas pessoas. No que tange a conteúdos orgânicos, nós temos trabalhado pra que todas as imagens, todos os conteúdos de IA produzidos por por nossa tecnologia, saia com a informação, sai com uma marca d'água. Hoje, não sei quantos estão aqui cientes, as marcas d'águas que que estão presentes em diversos conteúdos formulados produzidos por IA, são removíveis. É possível remover essas marcas d'águas por pessoas que são mal intencionadas por exemplo. E a nossa busca é para que as marcas d'águas que são colocadas através dos sistemas da Meta, não sejam retirados, para que assim né, outros sistemas possam reconhecer que aquele conteúdo foi modificado ou produzido pela inteligência artificial da Meta. Pra além disso, a Meta reconhece que é necessário fazer parcerias. E por isso a empresa faz parcerias com diversas outras empresas que produzem também conteúdos através de IA, para que uns possam reconhecer os sinais dos outros. Quando nós temos conteúdo de IA, esse conteúdo ele pode ser ele pode ser identificado como conteúdo produzido por IA, não só pela marca d'água, mas também por metadados, por uma marca que é legível então existem diversas formas de sinalizar conteúdos produzidos por IA, e hoje a Meta tem parcerias com diversas empresas para que nós possamos ler os finais uns dos outros. Lembrando que, muitas empresas produzem hoje materiais né pela inteligência artificial, e nesse sentido ainda é impossível entender todos as todas as tecnologias e todas as formas de identificação. O que traz uma complexidade né muito grande pra pra todo o ecossistema. Próximo. Quando nós falamos por exemplo de conteúdos de anúncios, é importante destacar que a Meta há muito tempo já atribui pra anúncios sociais e políticos uma etiqueta específica, não sei quantos estão acostumados a ver esses essas etiquetas, e e quando nós falamos em anúncios políticos e sociais que utilizaram inteligência artificial, a a Meta agora pede pra que os usuários ao subirem esses anúncios, informem que usaram inteligência artificial para esse fim. É lógico que a IA novamente pode ser utilizada para melhorar a qualidade da imagem, ou para melhorar a fluidez da conversa como foi citado aqui por outros painelistas. E daí nesse caso não seria necessário, mas quando aí é utilizada pra fazer entender que aquela fazer uma pessoa entender que discurso foi feito por outra ou dar a entender que houve uma situação que não aconteceu né, vamos supor uma festa que não aconteceu, uma reunião que não aconteceu, nós solicitamos que os usuários informem quando foi utilizado a IA, porque nós entendemos as limitações de tecnologia hoje existentes, e que a meta não é capaz de distinguir todos os tipos de a utilizados. Então existe aqui comprometimento dos usuários com a meta, de trazer essa informação, de trazer essa transparência e esse diálogo com os usuários. Por fim, pra gente Então a gente fez acordo chamado, dentro da conferência de Munique, no começo desse ano, pensando como que nós podemos como empresas né, vinte empresas assinaram esse acordo e como nós podemos ser pouco mais proativos e como nós podemos trabalhar de forma conjunta pra que a IA possa ser usada pra questões positivas né, evitar o uso enganoso da IA dentro das eleições, lembrando que já foi ressaltada aqui temos mais de quarenta eleições durante o ano. Bom eu finalizo aqui, e agradeço a atenção e a presença de todos nesse nesse horário, obrigado.",
      "speaker": {
        "name": "Mag Kang",
        "position": "Gerente Políticas Públicas | Estratégia e Engajamento na Meta"
      }
    },
    {
      "id": 4104322,
      "start_time": 1715257484,
      "duration": 14,
      "transcription": "Muito obrigado, Meg. Eu gostaria então agora de passar a palavra na sequência ao Marcelo do Google. Obrigado. Boa tarde a todos.",
      "summary": " Mestre de Cerimônias agradeceu a Meg e passou a palavra para Marcelo do Google. Boa tarde a todos.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104344,
      "start_time": 1715257498,
      "duration": 485,
      "transcription": "Todas queria cumprimentar todo mundo na figura do deputado Áureo, parabenizando ele pela realização desse seminário tão importante, e também agradecer o convite pra gente falar sobre assunto que é, que é, que é muito caro ao Google e acho que a todas as plataformas de tecnologia. Bom, apoiar e proteger as eleições do país é uma parte crucial do nosso compromisso com os brasileiros e com o processo democrático. Com os eleitores de mais de cinco mil e quinhentos municípios brasileiros, que vão às zonas em outubro, o nosso objetivo é continuar ampliando os esforços pra manter nossas plataformas seguras contra abusos e desinformação, mas ao mesmo tempo melhorando o acesso a fontes confiáveis e ajudando as pessoas a entenderem os conteúdos e imagem que elas encontram na internet pra que elas possam tomar as decisões da maneira mais bem informada. O combate à desinformação é trabalho crucial pra nossa empresa, cuja missão é exatamente organizar as informações do mundo e tornálas úteis e disponíveis para todos e todas. Mas infelizmente, não existe uma solução única, como a gente fala uma bala de prata, pra combater o fenômeno da desinformação. Por isso mesmo que o nosso trabalho, ele é, está baseado em alguns pilares sobre os quais eu vou falar a seguir. O primeiro deles é como é que a gente conecta pessoas com informações úteis e relevantes. E aí, trabalho que é crucial, eu diria, é espinha dorsal do Google, nessa as informações úteis e relevantes relacionadas às eleições, é o trabalho e a parceria que a gente tem com o TSE, que não começou agora, mas vem desde dois mil e catorze, está fazendo esse ano dez anos, e que na última eleição a gente lançou ferramentas como por exemplo, como tirar o tipo de eleitor ou como votar, onde diretamente na busca do Google, a gente ajudava as pessoas a encontrar as respostas, que precisavam pra poder participar do processo democrático que é a eleição. Durante o primeiro e segundo turno das últimas eleições, só pra vocês terem uma ideia, esses recursos foram vistos por quase duzentos e quarenta milhões de vezes. Nos últimos dias de votação, também da última votação, a gente entregou resultados na busca em tempo real, sobre as eleições com dados extraídos diretamente do TSE. Nos dias do primeiro e do segundo turno, o recurso representou aproximadamente trinta por cento do tráfego de pesquisa da busca do Google no Brasil. Mas além dessa parceria com o TSE, a gente também trabalha numa frente na nossa loja de aplicativos, a Google Play, e aí a gente criou uma coleção de de de aplicativos recomendando aqueles oficiais, tanto da Justiça Eleitoral, quanto os sites de notícias, organizações de verificação de fatos, com fins cívicos, incluindo aí o aplicativo eTítulo do TSE, o aplicativo de resultados também do TSE, mudamos mais e o comprova, que foram desenvolvidos com o apoio do Google. E no caso do Comprova, foi o primeiro aplicativo de verificação de fatos do Brasil. E ainda dentro desse pilar de conectar as pessoas com informações relevantes, a gente tem o objetivo também de fortalecer o ecossistema de checagem e verificação de conteúdos suspeitos na internet, e nesse sentido a gente lançou novas iniciativas na última eleição também, de apoio a esses profissionais no Brasil, com foco especial em eleições. A campanha por exemplo que a gente lançou de educação midiática chamada Conheça seu voto, alcançou mais de cem milhões de eleitores com dicas pra ajudálos a se informar e tomar essa decisão mais consciente sobre o voto. Bom o segundo pilar é como a gente ajuda as pessoas a entenderem o conteúdo gerado por IA, por inteligência artificial. Hoje em dia com mais pessoas usando inteligência artificial pra criar conteúdo, através de novas ferramentas, e políticas, o Google está aprimorando também mecanismos pra ajudar na identificação desse conteúdo gerado por IA. E como é que isso está acontecendo? A primeira forma é oferecendo contexto adicional de páginas e imagens. Hoje, a busca do Google oferece a possibilidade de que se tenha contexto sobre site antes mesmo de acessálo. Basta você clicar nos três pontinhos ao lado do nome da página dos resultados da pesquisa e selecionar a opção sobre esta página. Você verá aqui informações como a descrição do site na EQPedia quando disponível, e o que outras pessoas da própria web dizem sobre ele, com mais informação a gente entende que o usuário pode tomar uma decisão mais informada sobre a sua consulta e sobre AAA0 conteúdo daquela página. Mas além disso, também é possível obter mais detalhes no Google Imagens, com a opção sobre esta imagem. O recurso permite conhecer por exemplo, quando a imagem foi vista pela primeira vez na busca e se ela já foi publicada anteriormente. Descobrir, o que sites de notícia e agências de verificação já publicar à respeito daquela imagem, e conferir também, quando disponível os metadados que foram adicionados pelos criadores e editores de conteúdo à respeito daquela imagem. Uma segunda forma que a gente adota é uma abordagem de ser responsável para produtos com IA generativa. Por isso que a gente começou a implementar restrições sobre os tipos de perguntas relacionadas às eleições para as quais o JEMENAI, a nossa ferramenta de regenerativa, retornará respostas. Assumimos com muita responsabilidade a nossa, assumimos com seriedade a nossa responsabilidade de fornecer informações de alta qualidade pra que esses tipos de consultas, pra esses tipos de consultas, e trabalhamos continuamente para melhorar nossas proteções. Além disso, nosso recurso de verificação dupla do JEMENAI avalia se há conteúdo na web ou não para fundamentar a sua resposta. E a gente também está adotando rótulos de conteúdo no Youtube. Nossa plataforma de vídeo passou a exigir que todos os criadores identifiquem os conteúdos criados por IA, por inteligência artificial, ou com o uso de ferramentas de IA para facilitar o entendimento do público sobre se o vídeo foi manipulado ou modificado digitalmente, sinalizando assim conteúdo alterado ou sintético. E o último pilar que eu queria trazer aqui pra vocês, que é, não menos importante, é o da educação. Então eu queria falar pouquinho sobre a EducaMídia, que é o maior programa de alfabetização midiática do Brasil, e que conta com apoio de, já conta com apoio de cinco milhões de reais do Google através da nossa, da do nosso braço filantrópico, o Google ponto org. Na última eleição por exemplo, a o Educamídia focou em ensinar adolescentes idosos e populações vulneráveis a analisar e interpretar as informações que estão lendo ou vendo de uma forma mais crítica. O programa também luta pra inserir a educação midiática nos planos pedagógicos das escolas no Brasil. Nesse sentido, já alcançou desde a sua criação em dois mil e dezenove, mais de três milhões de estudantes e mais de dezessete mil educadores. Com o investimento do Google, Educamídia passou ampliou muito suas atividades levando a educação midiática pra várias regiões do Brasil. Enfim, todos esses esforços contribuem para o trabalho que realizamos em torno das eleições no Brasil. Reafirmo aqui que o Google continua empenhado em trabalhar com as autoridades locais, a indústria e a sociedade civil, para divulgar e conectar os eleitores a informações confiáveis e úteis online. Muito obrigado.",
      "summary": " Google se dedica a apoiar e defender eleições nacionais no Brasil, combatendo desinformação por meio de parcerias, fornecendo informações confiáveis, promovendo alfabetização midiática com EducaMídia e etiquetando conteúdo no YouTube.",
      "speaker": {
        "name": "Marcelo Lacerda",
        "position": "Diretor de Relações Governamentais e Políticas Públicas do Google"
      }
    },
    {
      "id": 4104319,
      "start_time": 1715257983,
      "duration": 9,
      "transcription": "Eu agradeço o Marcelo e chamo agora o Fernando do TikTok pra fazer suas considerações. Obrigado.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104346,
      "start_time": 1715257992,
      "duration": 462,
      "transcription": "Boa tarde a todos, eu sou Fernando Galo diretor de políticas públicas do TikTok no Brasil, tem aproximadamente uma década em que eu venho trabalhando nessa intersecção entre política pública e tecnologia. Queria agradecer pelo convite para participar, em nome do deputado Áureo, desse importante seminário sobre inteligência artificial e eleições. Como o Tik Tok é uma empresa pouco mais nova, e nem todo mundo está familiarizado com a nossa abordagem, eu queria muito brevemente apresentar o TikTok porque eu acho que isso vai ajudar a contextualizar o meu comentário e em seguida eu vou falar sobre o nosso trabalho de, relacionado à mídia sintética, inteligência artificial e eleições. E as intersecções entre eles. E no final também falar de importante anúncio a respeito de inteligência artificial que o TikTok está fazendo hoje. Então, bem, apresentando o TikTok, a gente é uma plataforma e uma empresa nova, nós temos apenas oito anos e a gente tem trabalhado a partir de uma abordagem colaborativa, seja com governos, com sociedade civil, com academia. A gente quer ser parceiro na construção de boas soluções para os problemas públicos que são causados pela própria pelo próprio desenvolvimento tecnológico. A plataforma TikTok, por sua vez, é uma plataforma de entretenimento, cuja missão é inspirar criatividade e trazer alegria. Mais de bilhão de pessoas usam o TikTok no autêntica ela precisa se sentir segura. E é a de maneira autêntica ela precisa se sentir segura. E é por isso que a gente tem trabalhado no desenvolvimento de políticas, de ferramentas, de processos pensando na segurança e na privacidade no TikTok, isso é ainda mais importante durante eventos como as eleições. Política e notícias não são digamos assim o carrochefe do TikTok, elas ocupam apenas uma pequena porcentagem do conteúdo, mas a gente sabe que esses temas certamente têm impacto maior durante períodos eleitorais, e a gente trabalha pra oferecer, equilíbrio entre essa as discussões sobre as eleições e ao mesmo tempo, permanecer uma plataforma que tem como objetivo unir as pessoas e não dividilas. Além da inteligência artificial que eu vou endereçar na sequência, eu queria destacar dois pontos da nossa abordagem sobre eleições que são diferentes do diferenciais do TikTok. O primeiro é que a gente não permite, nunca permitiu publicidade política ou eleitoral paga. Nós avaliamos que isso não combina com a experiência que as pessoas têm na nossa plataforma, e desde sempre a gente tomou a decisão de não fazer dinheiro com política e eleições no TikTok. O segundo ponto é a nossa abordagem de moderação de conteúdo em relação à desinformação eleitoral. A gente tem uma política que veda desinformação sobre processos cívicos eleitorais, independentemente da intenção, e a nossa opção de moderação é a remoção dos conteúdos e contas que violam as nossas regras, a gente não rotula conteúdo a gente remove. E aí então eu chego a questão da inteligência artificial e das mídias sintéticas e manipuladas. Toda a tecnologia, inclusive a inteligência artificial tem tem os dois lados né? E o que a gente tem que fazer é trabalhar pra maximizar as oportunidades que que advém das tecnologias e ao mesmo tempo, mitigar eventuais problemas que que surjam a partir do próprio desenvolvimento tecnológico. A gente tem uma política dedicada à mídia sintética nas nossas diretrizes de comunidade desde dois mil e vinte, E no ano passado a gente começou a implementar algumas atualizações nessa política. Também respondendo ao que, ao próprio desenvolvimento tecnológico que estava acontecendo no TikTok fora dele. A gente não permite mídia sintética que contenha a semelhança de qualquer figura privada real, ou qualquer pessoa menor de dezoito anos, e também não permite mídia sintética de figuras públicas, se o conteúdo for usado pra endossos ou violar qualquer outra política, não importa se o conteúdo é gerado por inteligência artificial ou não, se ele é conteúdo desinformativo, se ele é conteúdo de ódio, ele será removido. Pra finalizar, eu quero falar sobre uma parceria e contar sobre anúncio que estamos hoje. Na verdade, a parceria a Meg já comentou sobre ela, esforço de dezenove das principais empresas de tecnologia global, no combate a conteúdo eleitoral enganoso gerado por inteligência artificial esse anúncio que foi feito em fevereiro e o anúncio que a gente está fazendo hoje globalmente é o de que o TikTok está começando a rotular automaticamente conteúdos gerados por inteligência artificial, quando eles são carregados a partir de determinadas plataformas. Nós fomos a primeira plataforma a determinar que os criadores rotulassem conteúdos que foram completamente gerados ou significativamente ditados por inteligência artificial. E a gente exige que os criadores rotulem todo o conteúdo gerado por inteligência artificial que contenha imagens, áudio e vídeos realistas. E então a gente foi a primeira plataforma a oferecer uma uma uma ferramenta para que as pessoas fizessem essa sinalização. Isso pode ser feito através de rótulo ou uma legenda como sintético, falso, não real, alterado, enfim, essa ferramenta já foi utilizada por mais de trinta e sete milhões de criadores no TikTok. O que a gente está fazendo hoje é expandir a rotulagem. Ela vai ser uma rotulagem automática de conteúdos criados em outras plataformas, como as plataformas da OpenAI, da Adobe, e outras tantas empresas que são signatárias do C dois PA que é a coalizão pela proveniência e autenticidade de conteúdo. E aí fundamentalmente essas plataformas geram metadados e a gente consegue qualquer outra plataforma que esteja interoperável com esse sistema consegue saber que aquele conteúdo foi gerado por inteligência artificial e automaticamente pode sinalizar que aquele conteúdo foi fabricado desta forma. E nos próximos meses a gente vai começar a anexar anexar essa tecnologia aos nossos próprios conteúdos, que permanecerão nos metadados, após o download. O TikTok tem uma ferramenta de download e todo mundo sabe que eventualmente vídeos do TikTok vivem em outras plataformas. Também as pessoas vão poder checar se conteúdos do TikTok foram gerados por ferramentas de inteligência artificial. Da mesma forma, outras plataformas que vierem adotar esse rótulo que a gente está adotando hoje vão poder também dizer automaticamente que aquele conteúdo foi gerado, por inteligência artificial. E é isso. Agradeço, fico à disposição aqui. Muito obrigado.",
      "summary": " TikTok, um bilhão de usuários, prioriza parcerias tecnológicas para segurança e privacidade durante eleições. Contra publicidade política paga e desinformação eleitoral. Política contra mídia sintética com IA e parcerias com dezoito empresas globais de tecnologia para combater conteúdo eleitoral enganoso.",
      "speaker": {
        "name": "Fernando Galo",
        "position": "Diretor de Políticas Públicas TikTok"
      }
    },
    {
      "id": 4104326,
      "start_time": 1715258454,
      "duration": 13,
      "transcription": "Obrigado, Ana. Eu chamo agora o Caio, que vai fazer uma consideração breve, e posteriormente pra o encerramento eu vou chamar o deputado Ar Ribeira. Eu tenho",
      "summary": " Mestre de Cerimônias anuncia Caio para breve consideração, seguido pelo encerramento com a chamada do deputado Ar Ribeira.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104325,
      "start_time": 1715258467,
      "duration": 53,
      "transcription": "Artificial é utilizada pra essa moderação de conteúdo, seja pra rotulagem de conteúdos ou exclusão de posts de perfis, justamente porque delegar isso a uma pessoa humana é totalmente inviável, os algoritmos são muito úteis nessa moderação de conteúdo. Mas os algoritmos eles falham também, eles não são infalíveis. A inteligência artificial não funciona perfeitamente. Então, eu queria entender o que que cada uma das plataformas, qual qual tipo de medida é feito pra lidar com essa falibilidade dos algoritmos em moderar o conteúdo nas plataformas? Eu posso, você quer? Pode perguntar. Não,",
      "summary": " Plataformas utilizam artificial para moderação de conteúdo, mas algoritmos podem falhar. USP investiga como plataformas tratam falibilidade desses algoritmos.",
      "speaker": {
        "name": "Caio Missagia",
        "position": "USP"
      }
    },
    {
      "id": 4104330,
      "start_time": 1715258520,
      "duration": 94,
      "transcription": "Ia comentar duas coisas que que acho que estão relacionadas a isso. Hoje, por exemplo, isso é verdade pro TikTok e sei que é verdade pra outras plataformas. A arrasadora maioria de conteúdo que é removido por violação das políticas é feito por inteligência artificial, mas não é todo. É a razão por exemplo pela qual conta com mecanismos de denúncia, então todo o vídeo, toda a conta, pode ser denunciado pra nós. Oxalá que dia a gente chegue nos cem por cento, talvez isso seja impossível, talvez seja aspiracional, mas essa essa esse é procedimento que a gente usa sabendo que a inteligência artificial ou que os mecanismos de detecção que a gente tem não não são perfeitos embora sejam muito bons. E também por exemplo, mecanismos de apelação, tem algumas categorias de política que a gente consegue moderar conteúdo automaticamente. Os modelos geralmente são bastante acurados, mas às vezes eles falham. Então por exemplo, no TikTok a gente tem uma abordagem bastante rigorosa com a presença de menores na plataforma. Se a gente descobre que tem alguém com menos de treze anos usando o serviço, a gente derruba aquela conta. Eventualmente a gente derruba contas de maiores de treze anos. E aí a gente tem mecanismos de apelação, para que para que aquela conta seja restaurada. Então, evidentemente há o reconhecimento de que as tecnologias são muito boas, elas vão evoluindo com o tempo, mas elas não são perfeitas e por isso a gente tem ferramentas para para lidar com essas imperfeições. Vou aqui na ordem então.",
      "summary": " Inteligência artificial remove grande parte de conteúdo violador de políticas no TikTok. Denúncias e mecanismos de apelação existem para casos que a IA falha. A plataforma é rigorosa com menores de 13 anos, contas inadequadas são removidas e podem ser restauradas por apelação. A tecnologia é boa, mas não perfeita, e a plataforma se adapta às suas imperfeições.",
      "speaker": {
        "name": "Fernando Galo",
        "position": "Diretor de Políticas Públicas TikTok"
      }
    },
    {
      "id": 4104334,
      "start_time": 1715258614,
      "duration": 115,
      "transcription": "Como no slide que eu apresentei a gente trabalha com a IA, com os supervisores humanos, né, com uma equipe humana, e hoje pra vocês terem uma ideia de números, nós temos cerca de quinze mil revisores de conteúdos exclusivos pra Meta que trabalham em mais de vinte centros ao redor do mundo. Eles complementam então esse gap né, que foi aqui mencionado. E é importante, é muito importante a revisão dessas pessoas e a participação dessas pessoas, por quê? Porque elas refletem automaticamente junto à denúncia dos usuários, na melhor utilização da IA e na melhor resposta da IA, então eu vou dar exemplo, quando nós falamos sobre discurso de ódio por exemplo, a gente tinha a gente tem uma prevalência hoje de hoje de 0 vírgula 0 dois por cento de conteúdos com discurso de ódio na plataforma, isso quer dizer o quê? Que a cada dez mil conteúdos que podem ter discurso de ódio, apenas dois sobem. Esse é número maravilhoso, magnífico, que veio da utilização da inteligência artificial, e a melhoria através das denúncias e da revisão da nossa equipe humana. Pra além disso, quando a IA erra na moderação de conteúdo por exemplo, além dos mecanismos de apelação através do aplicativo, não sei quantos conhecem, nós temos o conselho de supervisão, também chamado de Oberça Iport, então a se a o seu conteúdo, o conteúdo do seu vizinho foi retirado ou não está sendo retirado e você não concorda, existe ainda a opção de pedir pra conselho independente pra que ele analise esse conteúdo. Então, existem várias formas da gente trabalhar na melhor utilização, não só da IA, mas na melhor moderação do conteúdo como todo. Bom, no nosso caso",
      "summary": " A Gerente de Políticas Públicas | Estratégia e Engajamento na Meta disse que Meta emprega aproximadamente 15 mil revisores de conteúdo em mais de 20 centros ao redor do mundo para complementar o uso da IA e refletir nas melhores respostas dela. A prevalência de discurso de ódio na plataforma é de 0,02%, graças ao uso da IA e revisão da equipe humana. Quando a IA erra na moderação de conteúdo, os usuários podem recorrer ao conselho de supervisão para uma análise independente.",
      "speaker": {
        "name": "Mag Kang",
        "position": "Gerente Políticas Públicas | Estratégia e Engajamento na Meta"
      }
    },
    {
      "id": 4104336,
      "start_time": 1715258729,
      "duration": 111,
      "transcription": "Parecido com o da das outras empresas Caio também, a gente usa exatamente uma combinação de máquina, né, que seria os algoritmos ou mecanismos de IA, e revisão humana, e assim como o Fernando falou no TikTok, a grande maioria da moderação que a gente faz, ou dos vídeos no caso do Youtube, a moderação no caso do Youtube, é feita, ela é feita automaticamente, mas a gente precisa de ter essa rede de proteção, que são a revisão né, são os revisores humanos, exatamente para aquilo que a máquina ainda não consegue enfim detectar e importante também Galo endereçou isso aqui, o Fernando endereçou isso aqui também, pra que a gente possa ter revisão até de conteúdo que eventualmente a gente remove e que não deveria ser removido. Né? E esse é processo contínuo e constante, acho que aqui uma predição minha, vai ser difícil a gente chegar no cem por cento, porque a, não só a questão do volume de conteúdo, no caso do Youtube são 500 horas de vídeo por minuto que são subidas na plataforma, mas também a a diversidade de conteúdo, então esses conteúdos vão mudando, né, e vão aparecendo e a gente sabe, né deputado, maus atores eles sempre vão existir, sempre vão tentar burlar as regras, então cabem e a gente estar sempre aprimorando obviamente, mas é uma é uma é uma corrida aí que a gente vive vinte e quatro por sete também igual meus colegas falaram aqui, pra poder detectar esses conteúdos nocivos nas nossas plataformas.",
      "summary": " Diretor de Relações Governamentais e Políticas Públicas do Google afirmou que a moderação de conteúdo no YouTube combina algoritmos e revisão humana, com foco na revisão de conteúdo removido indevidamente. Ele reconhece a dificuldade de alcançar 100% de eficácia devido ao volume e diversidade de conteúdo, bem como a existência contínua de atores mal-intencionados. Eles trabalham continuamente para detectar conteúdos nocivos em suas plataformas.",
      "speaker": {
        "name": "Marcelo Lacerda",
        "position": "Diretor de Relações Governamentais e Políticas Públicas do Google"
      }
    },
    {
      "id": 4104329,
      "start_time": 1715258840,
      "duration": 11,
      "transcription": "A todos. O deputado Aure agora fará algumas perguntas aos representantes de plataforma, e antes da gente proceder o encerramento do nascimento.",
      "summary": " Mestre de Cerimônias anuncia que o deputado Aure fará perguntas aos representantes de plataforma antes do encerramento do evento.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104332,
      "start_time": 1715258851,
      "duration": 105,
      "transcription": "Primeiro agradecer a todos que nos assiste pelos canais de transmissão, agradecer aqui a todos que participam do evento, mas queria deixar aqui algumas perguntas só pra que a gente pudesse esclarecer e facilitar. Dos problemas da remoção de conteúdo usado pela IA, é a falta de transparência do processo de tomada de decisão, pelo algoritmo para escolher post ou uma conta, o que pode acabar caracterizando uma censura indevida. Quais medidas as plataformas aqui representadas, tem tomado para garantir a transparência do devido processo aos usuários no caso de remoção de conteúdos e de perfis. Outra pergunta também, que eu peço aqui às plataformas para informarem sobre as tempestividade para a remoção de conteúdos suspeitos no período eleitoral. Período eleitoral nosso brasileiro hoje é de quarenta e cinco dias de eleição, já que o ritmo acelerado das campanha exige medidas rápidas. Exemplo conhecido de dano eleitoral foi na eleição de Los Waack, de onde o candidato perdeu a eleição nos dois últimos dias do pleito, uma informação forte, com a velocidade, se a gente não tem velocidade de retirar, pode criar risco muito grande à democracia então, essa fica minhas duas perguntas já agradecendo a participação de todos, no nosso evento pelo solidariedade aqui na Câmara dos Deputados. Posso posso começar",
      "summary": " Deputado questiona transparência processo remoção conteúdo e tempestividade retirada conteúdos suspeitos durante período eleitoral, alertando sobre risco à democracia.",
      "speaker": {
        "id": 160512,
        "name": "Aureo Ribeiro",
        "position": "Deputado",
        "slug": "aureo-ribeiro"
      }
    },
    {
      "id": 4104337,
      "start_time": 1715258956,
      "duration": 155,
      "transcription": "Já que eu fui o último na na na outra rodada. Deputado, sobre a questão da na transparência na aplicação das nossas políticas de moderação? Acho que alguns aspectos, o primeiro as políticas são todas públicas, elas são publicadas e toda vez que você cria canal, você uma conta nas nossas plataformas, você tem acesso a essas políticas, toda vez que essas políticas elas são atualizadas, elas são informadas também aos aos aos usuários e a toda vez que a gente tem a que a gente toma alguma medida em relação ao conteúdo ou canal específico esse usuário também é é informado. E é importante dizer que no caso, especificamente do Youtube, existe processo que o 0 processo é de aplicação das políticas ele é muito mais, ele é menos punitivo e mais educativo, Em que sentido? Se você bula uma dessas nossas políticas, a primeira coisa que você toma é aviso sobre a remoção, você não toma nenhuma penalidade, se você volta a infringir alguma dessas políticas, aí a segunda você toma uma penalidade, Se você volta pela terceira vez a infringir uma dessas políticas, aí sim você pode tomar uma penalidade maior ainda. E o que que a gente vê? O usuário que comete infração, a primeira infração, mais de noventa por cento não volta a cometer a segunda ou a terceira infração, ou seja, às vezes é até por falta de desconhecimento da política apesar delas serem públicas, que ocorrem essa esse tipo de de de infração. Então a gente adota uma abordagem menos punitiva e mais educativa, exatamente pra que o usuário conheça essas políticas e entenda quais são as regras das nossas plataformas. Em relação à remoção de conteúdo eleitoral, o senhor tem toda a razão, período eleitoral é período muito sensível, e é por isso mesmo que desde dois mil e catorze, a gente trabalha em estreita relação com o TSE, né? O TSE tem especificamente em relação a conteúdo desinformativo desde dois mil e dezesseis se eu não me engano, núcleo de combate à desinformação, e a gente durante todo o período eleitoral mantém canal de contato aberto e próximo do TSE exatamente pra que essas medidas sejam tomadas na tempestividade necessária. Deputada, obrigada",
      "summary": " Diretor de Relações Governamentais e Políticas Públicas do Google afirma: nossas políticas de moderação são públicas e educativas, enviamos avisos antes de penalidades e colaboramos com o TSE para remover conteúdo eleitoral desinformativo.",
      "speaker": {
        "name": "Marcelo Lacerda",
        "position": "Diretor de Relações Governamentais e Políticas Públicas do Google"
      }
    },
    {
      "id": 4104333,
      "start_time": 1715259111,
      "duration": 108,
      "transcription": "Pouquinho na linha, pouco na linha do que já foi falado aqui, as nossas políticas também estão disponíveis de forma transparente na plataforma, inclusive com exemplos do que é considerado gravíssimo e aí do que é removido, do que é considerado menos grave e aí ganharia por exemplo uma etiqueta, uma cobertura então, nós tentamos informar da melhor forma, inclusive com exemplos, pra que o usuário possa entender a política, não basta ter uma política né, que precisa ser entendida. Pra além disso, quando nós temos a estratégia de trabalhar com os secadores, se aquele conteúdo foi classificado como falso ou como boato, os secadores sempre põem uma justificativa, e a pessoa que postou vai receber a notificação, olha, o seu conteúdo foi classificado como falso. Qualquer outra pessoa que busque colocar o mesmo conteúdo no ar, vai receber a mesma notificação, olha, você está tentando subir aqui conteúdo que parece ser boato, que parece ser uma notícia falsa mas nós não temos certeza. E a justificativa sempre é embasada em em fontes que são aí buscadas pelos secadores, então aí também tem uma outra camada de transparência. Quando nós falamos sobre penalidades que Marcelo falou, nós também temos essa gradação e e os usuários acabam não sendo penalizados de pronto. E quando nós falamos também no período eleitoral, por entender a urgência, a importância, a demanda que isso exige, a meta tem de fato sido parceira com o TSE já há muitas eleições, nós somos grandes parceiros, nós temos canal dedicado, e nós temos esforço muito dedicado pro período das eleições, com transparência em relação a isso, com informação em relação a isso na nossa central de transparência.",
      "summary": " Políticas transparente na plataforma; fornecemos exemplos e justificativas; penalidades graduais; parceria com TSE para eleições; transparência no processo.",
      "speaker": {
        "name": "Mag Kang",
        "position": "Gerente Políticas Públicas | Estratégia e Engajamento na Meta"
      }
    },
    {
      "id": 4104338,
      "start_time": 1715259219,
      "duration": 110,
      "transcription": "Em adição ao que os colegas já disseram, acho que só dizer que, em relação ao devido processo, toda vez que uma conteúdo é moderado no TikTok, o usuário é alertado de que aquele conteúdo violou a política tal, com link pra política pra que na na linha do que o Marcelo falou ele possa entender o que que que que ele fez e a gente comunica ele, mas não só ele é comunicado como ele tem a opção de apelar da decisão, qualquer decisão nossa é passível de apelação, seja de moderação, no nível de conteúdo, seja no nível de conta. Inclusive, nos nossos relatórios de transparência a gente informa não só os conteúdos que foram moderados, mas quantas apelações foram, quantos conteúdos foram restaurados por terem sido moderados incorretamente? Como eu estava dizendo antes, a gente trabalha pra pra acertar cem por cento do tempo, Mas moderação de conteúdo em larguíssima escala como a que a gente faz, é bastante desafiador. A gente tem grande grau de acerto, mas não é perfeito. Em relação à tempestividade, só lembrar que, tanto em relação a ordens judiciais, né, a gente viu a resolução que o TSE exarou na no segundo turno, determinando que a gente removesse em até uma hora os conteúdos sob pena de uma de de multas altas, a gente assim cumpriu, mas também as próprias, a própria moderação que a gente faz, independentemente de ordem judicial, mais de noventa porcento do conteúdo que é removido é removido sem ter uma visualização, Que é também uma uma sinalização de de como a gente é tempestivo, na análise e na moderação desses desses conteúdos. É isso.",
      "summary": " Ao moderar conteúdo, TikTok alerta usuários com link para política violada e permite apelação. Relatam quantidade de apelações e conteúdos restaurados. Buscam acertar 100% do tempo, mas não é perfeito. A maioria do conteúdo é removido sem ser visualizado, demonstrando eficiência na tempestividade da moderação.",
      "speaker": {
        "name": "Fernando Galo",
        "position": "Diretor de Políticas Públicas TikTok"
      }
    },
    {
      "id": 4104328,
      "start_time": 1715259329,
      "duration": 4,
      "transcription": "Em adição ao que os colegas já disseram, acho que só dizer que, em relação ao devido processo, toda vez que uma conteúdo é moderado no TikTok, o usuário é alertado de que aquele conteúdo violou a política tal, com link pra política pra que na na linha do que o Marcelo falou ele possa entender o que que que que ele fez e a gente comunica ele, mas não só ele é comunicado como ele tem a opção de apelar a decisão, qualquer decisão nossa é passível de apelação, seja de moderação, no nível de conteúdo, seja no nível de conta. Inclusive, nos nossos relatórios de transparência a gente informa não só os conteúdos que foram moderados, mas quantas apelações foram, quantos conteúdos foram restaurados por terem sido moderados incorretamente? Como eu estava dizendo antes, a gente trabalha pra pra acertar cem por cento do tempo, Mas moderação de conteúdo em larguíssima escala como a que a gente faz, é bastante desafiador. A gente tem grande grau de acerto, mas não é perfeito. Em relação à tempestividade, só lembrar que, tanto em relação a ordens judiciais, né, a gente viu a resolução que o TSE exarou na no segundo turno, determinando que a gente removesse em até uma hora os conteúdos sob pena de uma de de multas altas, a gente assim cumpriu, mas também as próprias, a própria moderação que a gente faz, independentemente de ordem judicial, mais de noventa porcento do conteúdo que é removido é removido sem ter uma visualização, Que é também uma uma sinalização de de como a gente é tempestivo, na análise e na moderação desses desses conteúdos. É isso.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    },
    {
      "id": 4104341,
      "start_time": 1715259333,
      "duration": 71,
      "transcription": "Agradecer mais uma vez a todos os participantes, agradecer ao Solidariedade na liderança na Câmara dos Deputados pela oportunidade de debater drama tão fundamental para as eleições, eu acho que essa eleição vai ser uma eleição de muito aprendizado, vai ser uma eleição que a gente vai poder ter uma matéria discutindo na Câmara dos Deputados pra que a gente possa formatar uma regulação que não impeça tecnologia, mas sim que fomente debate promissor pra que a gente possa vencer os desafios que vamos encontrar nessa caminhada então é uma grande caminhada de muitas emoções que eu posso falar que a gente vai viver no Brasil porque a gente vai aprender, onde que o mundo está sofrendo não vai ser diferente aqui no nosso país, a gente vai aprender e vai poder contribuir com uma legislação, como contribuímos com a regulamentação da criptoeconomia, também contribui com a regulamentação da inteligência artificial, mas sem aqui prejudicar a tecnologia, mas sim incentivar investimentos no nosso país. Obrigado. Muito obrigado, deputado Álvaro Ribeiro, com isso",
      "summary": " Ele agradeceu a oportunidade de debater um assunto fundamental para as eleições, considerando que será uma eleição de aprendizagem e desafios, com uma lei promissora que permitirá o avanço da tecnologia no país, incentivando investimentos, sem prejudicá-la, assim como foi feito com a criptoeconomia e inteligência artificial. Obrigado.",
      "speaker": {
        "id": 160512,
        "name": "Aureo Ribeiro",
        "position": "Deputado",
        "slug": "aureo-ribeiro"
      }
    },
    {
      "id": 4104335,
      "start_time": 1715259404,
      "duration": 25,
      "transcription": "Agradecemos aos componentes da mesa, muito obrigado a todos, e encerramos o nosso evento sobre inteligência artificial e eleições. Muito obrigado, boa tarde.",
      "summary": " Mestre de Cerimônias agradeceu a mesa e encerrou evento sobre IA e eleições.",
      "speaker": {
        "name": "Ricardo Fernandes Paixão",
        "position": "Mestre de Cerimônias"
      }
    }
  ],
  "updated_at": 1715937526
}